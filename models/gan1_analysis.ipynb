{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b693cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-12 06:49:37.787776: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-12 06:49:41.635246: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.lines import Line2D\n",
    "import os\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\" # on NERSC filelocking is not allowed\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sklearn.metrics as sk\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "# Path to dir model.py lives in -------\n",
    "# NOTE: This needs to be modified to where your repo lives, path to /repo/path/VAE_FS/models/\n",
    "# If the jupyter notebook kernel is running from VAE_FS/models/ the\n",
    "# line below is not needed\n",
    "sys.path.append('/global/homes/j/jananinf/projs/VAE_FS/models/')\n",
    "\n",
    "# import the custom models and functions\n",
    "from models import Qmake_encoder_set_weights, Qmake_decoder_set_weights, Qmake_discriminator, VAE_GAN_Model\n",
    "from data_and_eval_utils import load_preprocessed_snl, plot_rocs, calc_anomaly_dist, AD_score_KL, AD_score_CKL, get_truth_and_scores, eval_rocs, SIG_KEYS\n",
    "# from models import VAE_Model_ATLAS_beta as NNmodel\n",
    "\n",
    "\n",
    "# # # Make notebook run on other GPUS. GPT's solution ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.set_visible_devices(gpus[0], 'GPU')  # change 1 to 0, 2, 3 as needed\n",
    "# # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08d5f07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONSTANTS IMPORTED:\n",
      "            NUM_TRAIN      = 10 # Number of iterations to train for.\n",
      "            # VAE Architecture\n",
      "            INPUT_SZ       = 57\n",
      "            H1_SZ          = 32 # Hidden layer 1 size\n",
      "            H2_SZ          = 16 # \"          \" 2 \"  \"\n",
      "            LATENT_SZ      = 3\n",
      "            # Discriminator Architecture # 8, 2 is on ATLAS-VAE-GAN\n",
      "            DISC_H1_SZ     = 8 # Size of first hidden layer of discriminator  \n",
      "            DISC_H2_SZ     = 2 # \"\" second hidden layer \"\"\n",
      "            # Training schedule and parameters\n",
      "            NUM_EPOCHS     = 100\n",
      "            STEPS_EPOCH    = 20 # Steps per epoch\n",
      "            BATCH_SIZE     = 1024\n",
      "            STOP_PATIENCE  = 40\n",
      "            LR_PATIENCE    = 20\n",
      "            LR             = 0.001 # Learning rate\n",
      "            REDUCE_LR_FACTOR = 0.5\n",
      "            VAL_SPLIT      = 0.2 # Validation split\n",
      "            CYCLE_LEN      = 20\n",
      "            SHUFFLE_BOOL   = True\n",
      "            # Hyperparameters\n",
      "            MIN_BETA       = 0\n",
      "            MAX_BETA       = 1\n",
      "            MIN_GAMMA      = 1\n",
      "            MAX_GAMMA      = 50\n"
     ]
    }
   ],
   "source": [
    "from gan_params import *\n",
    "print_base_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d35a016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = \"/global/cfs/cdirs/m2616/jananinf/projsIO/VAE_FS/\" # Updated to NERSC\n",
    "SAVE_PATH = home_path+f\"GAN_trainings/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f3d397",
   "metadata": {},
   "source": [
    "### Loss plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91d9f9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# History Keys\n",
    "keys = [\n",
    "        'loss'               # VAE total loss term.\n",
    "        ,'reco_loss'         # VAE loss term\n",
    "        ,'kl_loss'           # VAE Loss term\n",
    "        ,'disc_loss'         # VAE loss due to discriminator \"failure to fool disc\"\n",
    "        # # ,'raw_loss'          # Reco_loss + kl_loss\n",
    "        ,'w_kl_loss'         # kl_loss * beta\n",
    "        ,'w_disc_loss'       # disc_loss * gamma\n",
    "        ,'d_loss'\n",
    "        # Validation version\n",
    "        ,'val_loss'          \n",
    "        ,'val_reco_loss'\n",
    "        ,'val_kl_loss'\n",
    "        ,'val_disc_loss'\n",
    "        # ,'val_raw_loss'\n",
    "        ,'val_w_kl_loss'\n",
    "        ,'val_w_disc_loss'\n",
    "        ,'val_d_loss'\n",
    "        # --\n",
    "        # ,'beta'              # hyperparameter\n",
    "        # ,'gamma'             # hyperparameter\n",
    "        # ,'val_gamma'         # hyperparameter\n",
    "        # ,'val_beta'          # hyperparameter\n",
    "        # ,'lr'              # learning rate\n",
    "        ]\n",
    "\n",
    "color_key = {\n",
    "             'loss' : 'k'               # VAE total loss term.\n",
    "            ,'val_loss' : 'k'         \n",
    "            ,'reco_loss': 'tab:blue'         # VAE loss term\n",
    "            ,'val_reco_loss' : 'tab:blue'\n",
    "            ,'kl_loss': 'crimson'          # VAE Loss term\n",
    "            ,'val_kl_loss': 'crimson'\n",
    "            ,'disc_loss' : 'c'        # VAE loss due to discriminator \"failure to fool disc\"\n",
    "            ,'val_disc_loss' : 'c'\n",
    "            ,'w_kl_loss'  : 'tab:orange'        # kl_loss * beta\n",
    "            ,'val_w_kl_loss' : 'tab:orange'\n",
    "            ,'w_disc_loss'  : 'tab:green'     # disc_loss * gamma\n",
    "            ,'val_w_disc_loss' : 'tab:green'\n",
    "            ,'d_loss': 'r'\n",
    "            ,'val_d_loss' :'r'\n",
    "        }\n",
    "# d_loss : discriminator loss\n",
    "# loss : generator total loss\n",
    "# raw_loss : reconstruction and kl_loss without beta weighting\n",
    "\n",
    "\n",
    "# # Generate cleaner legend\n",
    "# proxy_lines = {}\n",
    "# for key in keys:\n",
    "#     base_key = key.replace('val_', '')  # Strip 'val_' to group them\n",
    "#     if base_key not in proxy_lines and key in color_key:\n",
    "#         proxy_lines[base_key] = Line2D([0], [0], \n",
    "#                                     color=color_key[key], \n",
    "#                                     lw=2, \n",
    "#                                     label=base_key)\n",
    "# clean_leg = list(proxy_lines.values())\n",
    "# for att_n in range(6, 38): # plot all attempts. most recent is 18.\n",
    "#     att_path = SAVE_PATH + f\"attempt{att_n}/\"\n",
    "\n",
    "#     # Make folder for loss plots if it doesn't exist\n",
    "#     plot_dir = os.path.join(SAVE_PATH, f\"loss_plots/attempt{att_n}/\")\n",
    "#     os.makedirs(plot_dir, exist_ok=True)\n",
    "    \n",
    "#     for i in range(10): # Currently only training 10 models at a time.\n",
    "#         save_path = att_path + f\"n_{i}/\"\n",
    "#         with open(save_path + 'training_history.pkl', 'rb') as f:\n",
    "#             history = pkl.load(f)\n",
    "    \n",
    "        \n",
    "#         # Plot training losses\n",
    "#         # fig, (ax, ax2) = plt.subplots(nrows=2, sharex=True, figsize=(8,10))\n",
    "#         fig = plt.figure(figsize=(12, 8))\n",
    "#         gs = gridspec.GridSpec(2, 1, height_ratios=[3, 1])  # 3:1 means top gets 75%, bottom 25%\n",
    "\n",
    "#         ax = fig.add_subplot(gs[0])\n",
    "#         ax2 = fig.add_subplot(gs[1], sharex=ax)\n",
    "\n",
    "#         # Calculate fractional contributions to total VAE loss\n",
    "#         loss = np.array(history['loss'])\n",
    "#         reco_loss = np.array(history['reco_loss'])\n",
    "#         beta = np.array(history['beta'])\n",
    "#         reco_loss_frac = (reco_loss * (1 - beta))/loss\n",
    "\n",
    "#         w_kl_loss_frac = np.array(history['w_kl_loss'])/loss\n",
    "#         w_disc_loss_frac = np.array(history['w_disc_loss'])/loss\n",
    "#         ax2.plot(reco_loss_frac, label='reco_loss_frac')\n",
    "#         ax2.plot(w_kl_loss_frac, label='w_kl_loss_frac')\n",
    "#         ax2.plot(w_disc_loss_frac, label='w_disc_loss_frac')\n",
    "\n",
    "#         # Tweak fractional plot\n",
    "#         # ax2.set_ylim((0,1))\n",
    "#         ax2.set_ylabel('Approximate\\nTotal VAE Loss fraction')\n",
    "#         # ax2.tick_params(axis='y', labelcolor='b')\n",
    "#         ax2.legend()\n",
    "#         ax2.grid()\n",
    "#         ax2.set_xlabel('Epoch')\n",
    "\n",
    "#         for key in keys:\n",
    "#             if key == 'lr' or history.get(key) == None:\n",
    "#                 continue\n",
    "#             ax.plot(np.abs(history[key]),\n",
    "#                      label=key, \n",
    "#                      linestyle = \"dashed\" if key[0:3] == 'val' else \"solid\",\n",
    "#                      marker= \"x\" if key[0:3] == 'val' else \"o\",\n",
    "#                      markersize=6.5,\n",
    "#                      color=color_key[key])\n",
    "    \n",
    "#         # Customize the plot\n",
    "#         ax.set_title(f'Training and Validation Losses, Attempt: {att_n} Run: {i}')\n",
    "#         ax.set_ylabel('Loss')\n",
    "#         # ax.tick_params(axis='y', labelcolor='r')\n",
    "#         # ax.legend()\n",
    "#         ax.grid(True)\n",
    "#         ax.set_yscale('log')\n",
    "#         ax.legend(handles=clean_leg, title=\"○ = train, x = val\")\n",
    "#         plt.savefig(SAVE_PATH + f\"loss_plots/attempt{att_n}/\" + f\"loss_attempt_{att_n}_run_{i}.png\", bbox_inches='tight')\n",
    "#         # plt.show()\n",
    "#         plt.close(fig)\n",
    "#     print(f\"Attempt {att_n} plotting complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9774118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from preprocessed_SNL_data.h5\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = load_preprocessed_snl()\n",
    "# X_train = data['X_train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d161259d",
   "metadata": {},
   "source": [
    "##### Calculate Anomaly scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae308f",
   "metadata": {},
   "source": [
    "After inspecting the graphs a few notable models remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57801db5",
   "metadata": {},
   "outputs": [],
   "source": [
    " # mins 88, 90, 89, 79 for AUC. \n",
    "# # 16 did the best AUC and I think also has higher TPR @ target FPR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811d8625",
   "metadata": {},
   "source": [
    "Generate ROC Curves for all trained iterations of the model. Save them and \n",
    "generate a list of of models with their AUC to rank them later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b950190f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-12 06:50:08.118889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 890 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:c3:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "new_enc = Qmake_encoder_set_weights(INPUT_SZ, H1_SZ, H2_SZ, LATENT_SZ)\n",
    "new_dec = Qmake_decoder_set_weights(INPUT_SZ, H1_SZ, H2_SZ, LATENT_SZ)\n",
    "new_disc = Qmake_discriminator(INPUT_SZ, DISC_H1_SZ, DISC_H2_SZ)\n",
    "new_VAE = VAE_GAN_Model(new_enc, new_dec, new_disc)\n",
    "opt = keras.optimizers.Adam(learning_rate=LR) # These help silence benign warnings and is cleaner ----\n",
    "new_VAE.compile(optimizer=opt)                # ---\n",
    "\n",
    "\n",
    "FIG_SAVE_PATH = SAVE_PATH + \"roc_plots/\"\n",
    "\n",
    "# for att_n in range(6,17): # Splitting everythingup\n",
    "#     roc_results = {}\n",
    "#     bad_iters = {}\n",
    "\n",
    "#     # Iterate through its iterations\n",
    "#     fig_save_path = FIG_SAVE_PATH + f\"attempt{att_n}/\"\n",
    "\n",
    "#     for i in range(NUM_TRAIN):\n",
    "#         save_path = SAVE_PATH + f\"attempt{att_n}/n_{i}/\"\n",
    "\n",
    "#         new_VAE.load_weights(save_path)\n",
    "#         just_enc = new_VAE.get_layer(\"encoder\") # We only need encoder output\n",
    "\n",
    "#         roc_perfs = eval_rocs(just_enc, data, AD_score_CKL)\n",
    "\n",
    "#         if roc_perfs is None:\n",
    "#             print(f\"Bad Iteration. Attempt: {att_n}, Iteration: {i}.\")\n",
    "#             bad_iters.setdefault(f\"Attempt{att_n}\", []).append(i) # Create the entry and list if it doesn't exit, otherwise append it to the current list of that entry\n",
    "#             continue\n",
    "#         # Save its auc performance\n",
    "#         roc_results[f\"Attempt{att_n}_iter_{i}\"] = {k: roc_perfs[k]['auc'] for k in SIG_KEYS.keys()}\n",
    "\n",
    "#         # Commented out because we don't need to make the plots rn\n",
    "#         # Make folder for roc plots if it doesn't exist\n",
    "#         # plot_dir = os.path.join(fig_save_path)\n",
    "#         # os.makedirs(plot_dir, exist_ok=True)\n",
    "#         # f = plot_rocs(roc_perfs, f\"ROC Curves. CKL as Anomaly Score. Attempt: {att_n}, Iter: {i}\")\n",
    "#         # f.savefig(fig_save_path + f\"roc_att{att_n}_iter{i}.png\", bbox_inches = 'tight')\n",
    "#         # plt.close(f)\n",
    "#         # print(f\"Roc curve plotted and saved. for Attempt: {att_n}, iter: {i}!\")\n",
    "\n",
    "#         print(f\"Completed Attempt: {att_n} Iter: {i}\")\n",
    "        \n",
    "#     with open(SAVE_PATH + f\"temp_pkls/roc_results_att_{att_n}.pkl\", \"wb\") as f:\n",
    "#         pkl.dump([bad_iters, roc_results], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de108a9b-c6b9-4ed9-8222-b36226412aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.DataFrame({})\n",
    "stats = pd.DataFrame({})\n",
    "\n",
    "for i in range(6, 50):\n",
    "    with open(SAVE_PATH + f\"temp_pkls/roc_results_att_{i}.pkl\", \"rb\") as f:\n",
    "        roc_result = pkl.load(f)[1] # Load just the roc results\n",
    "    temp = pd.DataFrame(roc_result).transpose()\n",
    "    all_results = pd.concat([all_results, temp], axis=0)\n",
    "    # Some quick stats while we're at it.\n",
    "    temp_stats = {}\n",
    "    for c in temp.columns:\n",
    "        temp_stats[c] = temp[c].mean()\n",
    "    temp_stats = pd.DataFrame(temp_stats, index = [f\"attempt_{i}\"])\n",
    "    # temp_stats[\"RMS_AUC\"] = np.sqrt(temp.Ato4l**2 + temp.hToTauTau**2 + temp.hChToTauNu**2 + temp.leptoquark**2)\n",
    "    stats = pd.concat([stats, temp_stats], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "757eb032",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[\"RMS_AUC\"] = np.sqrt((stats.Ato4l**2 + stats.hToTauTau**2 + stats.hChToTauNu**2 + stats.leptoquark**2)/4)\n",
    "stats[\"MEAN_AUC\"] = stats.iloc[:, :4].mean(axis=1)\n",
    "stats[\"SPREAD\"] = stats.iloc[:, :4].max(axis=1) - stats.iloc[:, :4].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1091288d-e4a7-4586-8bc5-e6082fa74e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ato4l</th>\n",
       "      <th>hToTauTau</th>\n",
       "      <th>hChToTauNu</th>\n",
       "      <th>leptoquark</th>\n",
       "      <th>RMS_AUC</th>\n",
       "      <th>MEAN_AUC</th>\n",
       "      <th>SPREAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>attempt_47</th>\n",
       "      <td>0.911347</td>\n",
       "      <td>0.759736</td>\n",
       "      <td>0.859302</td>\n",
       "      <td>0.841065</td>\n",
       "      <td>0.844622</td>\n",
       "      <td>0.842862</td>\n",
       "      <td>0.151611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_48</th>\n",
       "      <td>0.909307</td>\n",
       "      <td>0.755611</td>\n",
       "      <td>0.857954</td>\n",
       "      <td>0.838085</td>\n",
       "      <td>0.842060</td>\n",
       "      <td>0.840239</td>\n",
       "      <td>0.153696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_44</th>\n",
       "      <td>0.904997</td>\n",
       "      <td>0.749910</td>\n",
       "      <td>0.857920</td>\n",
       "      <td>0.836969</td>\n",
       "      <td>0.839334</td>\n",
       "      <td>0.837449</td>\n",
       "      <td>0.155088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_20</th>\n",
       "      <td>0.900845</td>\n",
       "      <td>0.753955</td>\n",
       "      <td>0.850843</td>\n",
       "      <td>0.831969</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.834403</td>\n",
       "      <td>0.146890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_39</th>\n",
       "      <td>0.899647</td>\n",
       "      <td>0.744628</td>\n",
       "      <td>0.854362</td>\n",
       "      <td>0.828230</td>\n",
       "      <td>0.833627</td>\n",
       "      <td>0.831717</td>\n",
       "      <td>0.155019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_6</th>\n",
       "      <td>0.898694</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.841409</td>\n",
       "      <td>0.822481</td>\n",
       "      <td>0.829931</td>\n",
       "      <td>0.828237</td>\n",
       "      <td>0.148330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_29</th>\n",
       "      <td>0.895840</td>\n",
       "      <td>0.740885</td>\n",
       "      <td>0.846353</td>\n",
       "      <td>0.827478</td>\n",
       "      <td>0.829529</td>\n",
       "      <td>0.827639</td>\n",
       "      <td>0.154955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_43</th>\n",
       "      <td>0.897580</td>\n",
       "      <td>0.745341</td>\n",
       "      <td>0.842612</td>\n",
       "      <td>0.822376</td>\n",
       "      <td>0.828776</td>\n",
       "      <td>0.826977</td>\n",
       "      <td>0.152239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_40</th>\n",
       "      <td>0.893677</td>\n",
       "      <td>0.740226</td>\n",
       "      <td>0.845324</td>\n",
       "      <td>0.824270</td>\n",
       "      <td>0.827736</td>\n",
       "      <td>0.825874</td>\n",
       "      <td>0.153451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_26</th>\n",
       "      <td>0.892208</td>\n",
       "      <td>0.744810</td>\n",
       "      <td>0.843951</td>\n",
       "      <td>0.822187</td>\n",
       "      <td>0.827500</td>\n",
       "      <td>0.825789</td>\n",
       "      <td>0.147398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_22</th>\n",
       "      <td>0.898800</td>\n",
       "      <td>0.738120</td>\n",
       "      <td>0.840920</td>\n",
       "      <td>0.817603</td>\n",
       "      <td>0.825876</td>\n",
       "      <td>0.823861</td>\n",
       "      <td>0.160680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_9</th>\n",
       "      <td>0.892216</td>\n",
       "      <td>0.734994</td>\n",
       "      <td>0.843552</td>\n",
       "      <td>0.818168</td>\n",
       "      <td>0.824203</td>\n",
       "      <td>0.822232</td>\n",
       "      <td>0.157222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_42</th>\n",
       "      <td>0.894896</td>\n",
       "      <td>0.735754</td>\n",
       "      <td>0.841989</td>\n",
       "      <td>0.815858</td>\n",
       "      <td>0.824127</td>\n",
       "      <td>0.822124</td>\n",
       "      <td>0.159141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_24</th>\n",
       "      <td>0.895400</td>\n",
       "      <td>0.732414</td>\n",
       "      <td>0.834604</td>\n",
       "      <td>0.816323</td>\n",
       "      <td>0.821754</td>\n",
       "      <td>0.819685</td>\n",
       "      <td>0.162986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_45</th>\n",
       "      <td>0.893316</td>\n",
       "      <td>0.727229</td>\n",
       "      <td>0.833935</td>\n",
       "      <td>0.813543</td>\n",
       "      <td>0.819173</td>\n",
       "      <td>0.817006</td>\n",
       "      <td>0.166086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_13</th>\n",
       "      <td>0.894855</td>\n",
       "      <td>0.725258</td>\n",
       "      <td>0.837199</td>\n",
       "      <td>0.808336</td>\n",
       "      <td>0.818699</td>\n",
       "      <td>0.816412</td>\n",
       "      <td>0.169598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_30</th>\n",
       "      <td>0.890842</td>\n",
       "      <td>0.728019</td>\n",
       "      <td>0.838809</td>\n",
       "      <td>0.807468</td>\n",
       "      <td>0.818416</td>\n",
       "      <td>0.816285</td>\n",
       "      <td>0.162823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_27</th>\n",
       "      <td>0.891951</td>\n",
       "      <td>0.732672</td>\n",
       "      <td>0.827944</td>\n",
       "      <td>0.808821</td>\n",
       "      <td>0.817323</td>\n",
       "      <td>0.815347</td>\n",
       "      <td>0.159279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_41</th>\n",
       "      <td>0.887794</td>\n",
       "      <td>0.732517</td>\n",
       "      <td>0.828157</td>\n",
       "      <td>0.809684</td>\n",
       "      <td>0.816424</td>\n",
       "      <td>0.814538</td>\n",
       "      <td>0.155277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_18</th>\n",
       "      <td>0.893254</td>\n",
       "      <td>0.725525</td>\n",
       "      <td>0.833146</td>\n",
       "      <td>0.803093</td>\n",
       "      <td>0.815994</td>\n",
       "      <td>0.813755</td>\n",
       "      <td>0.167729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_10</th>\n",
       "      <td>0.886726</td>\n",
       "      <td>0.730937</td>\n",
       "      <td>0.828192</td>\n",
       "      <td>0.804781</td>\n",
       "      <td>0.814575</td>\n",
       "      <td>0.812659</td>\n",
       "      <td>0.155790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_12</th>\n",
       "      <td>0.890120</td>\n",
       "      <td>0.726664</td>\n",
       "      <td>0.824749</td>\n",
       "      <td>0.804001</td>\n",
       "      <td>0.813477</td>\n",
       "      <td>0.811383</td>\n",
       "      <td>0.163456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_37</th>\n",
       "      <td>0.889120</td>\n",
       "      <td>0.721572</td>\n",
       "      <td>0.823528</td>\n",
       "      <td>0.805506</td>\n",
       "      <td>0.812133</td>\n",
       "      <td>0.809931</td>\n",
       "      <td>0.167548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_11</th>\n",
       "      <td>0.882154</td>\n",
       "      <td>0.724770</td>\n",
       "      <td>0.823742</td>\n",
       "      <td>0.806771</td>\n",
       "      <td>0.811313</td>\n",
       "      <td>0.809359</td>\n",
       "      <td>0.157384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_25</th>\n",
       "      <td>0.887979</td>\n",
       "      <td>0.723006</td>\n",
       "      <td>0.820615</td>\n",
       "      <td>0.802080</td>\n",
       "      <td>0.810553</td>\n",
       "      <td>0.808420</td>\n",
       "      <td>0.164972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_28</th>\n",
       "      <td>0.881671</td>\n",
       "      <td>0.722414</td>\n",
       "      <td>0.824546</td>\n",
       "      <td>0.801024</td>\n",
       "      <td>0.809435</td>\n",
       "      <td>0.807414</td>\n",
       "      <td>0.159257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_21</th>\n",
       "      <td>0.884325</td>\n",
       "      <td>0.722226</td>\n",
       "      <td>0.818801</td>\n",
       "      <td>0.800340</td>\n",
       "      <td>0.808489</td>\n",
       "      <td>0.806423</td>\n",
       "      <td>0.162099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_23</th>\n",
       "      <td>0.885387</td>\n",
       "      <td>0.713650</td>\n",
       "      <td>0.827272</td>\n",
       "      <td>0.797824</td>\n",
       "      <td>0.808410</td>\n",
       "      <td>0.806033</td>\n",
       "      <td>0.171737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_49</th>\n",
       "      <td>0.880051</td>\n",
       "      <td>0.716481</td>\n",
       "      <td>0.825579</td>\n",
       "      <td>0.797114</td>\n",
       "      <td>0.806970</td>\n",
       "      <td>0.804806</td>\n",
       "      <td>0.163570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_14</th>\n",
       "      <td>0.872739</td>\n",
       "      <td>0.730812</td>\n",
       "      <td>0.811894</td>\n",
       "      <td>0.801339</td>\n",
       "      <td>0.805772</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.141926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_19</th>\n",
       "      <td>0.881678</td>\n",
       "      <td>0.719308</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.793235</td>\n",
       "      <td>0.804472</td>\n",
       "      <td>0.802381</td>\n",
       "      <td>0.162370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_31</th>\n",
       "      <td>0.883717</td>\n",
       "      <td>0.715726</td>\n",
       "      <td>0.810919</td>\n",
       "      <td>0.790450</td>\n",
       "      <td>0.802437</td>\n",
       "      <td>0.800203</td>\n",
       "      <td>0.167990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_8</th>\n",
       "      <td>0.868102</td>\n",
       "      <td>0.720094</td>\n",
       "      <td>0.819659</td>\n",
       "      <td>0.787897</td>\n",
       "      <td>0.800743</td>\n",
       "      <td>0.798938</td>\n",
       "      <td>0.148008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_38</th>\n",
       "      <td>0.871812</td>\n",
       "      <td>0.698122</td>\n",
       "      <td>0.804211</td>\n",
       "      <td>0.770694</td>\n",
       "      <td>0.788694</td>\n",
       "      <td>0.786210</td>\n",
       "      <td>0.173689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_32</th>\n",
       "      <td>0.867878</td>\n",
       "      <td>0.706159</td>\n",
       "      <td>0.792924</td>\n",
       "      <td>0.769031</td>\n",
       "      <td>0.786131</td>\n",
       "      <td>0.783998</td>\n",
       "      <td>0.161720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_36</th>\n",
       "      <td>0.874411</td>\n",
       "      <td>0.689405</td>\n",
       "      <td>0.791032</td>\n",
       "      <td>0.762861</td>\n",
       "      <td>0.782234</td>\n",
       "      <td>0.779427</td>\n",
       "      <td>0.185006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_33</th>\n",
       "      <td>0.847265</td>\n",
       "      <td>0.697386</td>\n",
       "      <td>0.790471</td>\n",
       "      <td>0.767581</td>\n",
       "      <td>0.777533</td>\n",
       "      <td>0.775676</td>\n",
       "      <td>0.149879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_7</th>\n",
       "      <td>0.850461</td>\n",
       "      <td>0.684661</td>\n",
       "      <td>0.787588</td>\n",
       "      <td>0.752970</td>\n",
       "      <td>0.771250</td>\n",
       "      <td>0.768920</td>\n",
       "      <td>0.165801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_46</th>\n",
       "      <td>0.860616</td>\n",
       "      <td>0.670527</td>\n",
       "      <td>0.779215</td>\n",
       "      <td>0.740867</td>\n",
       "      <td>0.765886</td>\n",
       "      <td>0.762806</td>\n",
       "      <td>0.190089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_15</th>\n",
       "      <td>0.872192</td>\n",
       "      <td>0.640266</td>\n",
       "      <td>0.775012</td>\n",
       "      <td>0.722147</td>\n",
       "      <td>0.757099</td>\n",
       "      <td>0.752404</td>\n",
       "      <td>0.231926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_34</th>\n",
       "      <td>0.849704</td>\n",
       "      <td>0.662971</td>\n",
       "      <td>0.748506</td>\n",
       "      <td>0.730411</td>\n",
       "      <td>0.750881</td>\n",
       "      <td>0.747898</td>\n",
       "      <td>0.186733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_35</th>\n",
       "      <td>0.837422</td>\n",
       "      <td>0.656301</td>\n",
       "      <td>0.738936</td>\n",
       "      <td>0.708172</td>\n",
       "      <td>0.738163</td>\n",
       "      <td>0.735208</td>\n",
       "      <td>0.181120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt_17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Ato4l  hToTauTau  hChToTauNu  leptoquark   RMS_AUC  MEAN_AUC  \\\n",
       "attempt_47  0.911347   0.759736    0.859302    0.841065  0.844622  0.842862   \n",
       "attempt_48  0.909307   0.755611    0.857954    0.838085  0.842060  0.840239   \n",
       "attempt_44  0.904997   0.749910    0.857920    0.836969  0.839334  0.837449   \n",
       "attempt_20  0.900845   0.753955    0.850843    0.831969  0.836074  0.834403   \n",
       "attempt_39  0.899647   0.744628    0.854362    0.828230  0.833627  0.831717   \n",
       "attempt_6   0.898694   0.750365    0.841409    0.822481  0.829931  0.828237   \n",
       "attempt_29  0.895840   0.740885    0.846353    0.827478  0.829529  0.827639   \n",
       "attempt_43  0.897580   0.745341    0.842612    0.822376  0.828776  0.826977   \n",
       "attempt_40  0.893677   0.740226    0.845324    0.824270  0.827736  0.825874   \n",
       "attempt_26  0.892208   0.744810    0.843951    0.822187  0.827500  0.825789   \n",
       "attempt_22  0.898800   0.738120    0.840920    0.817603  0.825876  0.823861   \n",
       "attempt_9   0.892216   0.734994    0.843552    0.818168  0.824203  0.822232   \n",
       "attempt_42  0.894896   0.735754    0.841989    0.815858  0.824127  0.822124   \n",
       "attempt_24  0.895400   0.732414    0.834604    0.816323  0.821754  0.819685   \n",
       "attempt_45  0.893316   0.727229    0.833935    0.813543  0.819173  0.817006   \n",
       "attempt_13  0.894855   0.725258    0.837199    0.808336  0.818699  0.816412   \n",
       "attempt_30  0.890842   0.728019    0.838809    0.807468  0.818416  0.816285   \n",
       "attempt_27  0.891951   0.732672    0.827944    0.808821  0.817323  0.815347   \n",
       "attempt_41  0.887794   0.732517    0.828157    0.809684  0.816424  0.814538   \n",
       "attempt_18  0.893254   0.725525    0.833146    0.803093  0.815994  0.813755   \n",
       "attempt_10  0.886726   0.730937    0.828192    0.804781  0.814575  0.812659   \n",
       "attempt_12  0.890120   0.726664    0.824749    0.804001  0.813477  0.811383   \n",
       "attempt_37  0.889120   0.721572    0.823528    0.805506  0.812133  0.809931   \n",
       "attempt_11  0.882154   0.724770    0.823742    0.806771  0.811313  0.809359   \n",
       "attempt_25  0.887979   0.723006    0.820615    0.802080  0.810553  0.808420   \n",
       "attempt_28  0.881671   0.722414    0.824546    0.801024  0.809435  0.807414   \n",
       "attempt_21  0.884325   0.722226    0.818801    0.800340  0.808489  0.806423   \n",
       "attempt_23  0.885387   0.713650    0.827272    0.797824  0.808410  0.806033   \n",
       "attempt_49  0.880051   0.716481    0.825579    0.797114  0.806970  0.804806   \n",
       "attempt_14  0.872739   0.730812    0.811894    0.801339  0.805772  0.804196   \n",
       "attempt_19  0.881678   0.719308    0.815301    0.793235  0.804472  0.802381   \n",
       "attempt_31  0.883717   0.715726    0.810919    0.790450  0.802437  0.800203   \n",
       "attempt_8   0.868102   0.720094    0.819659    0.787897  0.800743  0.798938   \n",
       "attempt_38  0.871812   0.698122    0.804211    0.770694  0.788694  0.786210   \n",
       "attempt_32  0.867878   0.706159    0.792924    0.769031  0.786131  0.783998   \n",
       "attempt_36  0.874411   0.689405    0.791032    0.762861  0.782234  0.779427   \n",
       "attempt_33  0.847265   0.697386    0.790471    0.767581  0.777533  0.775676   \n",
       "attempt_7   0.850461   0.684661    0.787588    0.752970  0.771250  0.768920   \n",
       "attempt_46  0.860616   0.670527    0.779215    0.740867  0.765886  0.762806   \n",
       "attempt_15  0.872192   0.640266    0.775012    0.722147  0.757099  0.752404   \n",
       "attempt_34  0.849704   0.662971    0.748506    0.730411  0.750881  0.747898   \n",
       "attempt_35  0.837422   0.656301    0.738936    0.708172  0.738163  0.735208   \n",
       "attempt_16       NaN        NaN         NaN         NaN       NaN       NaN   \n",
       "attempt_17       NaN        NaN         NaN         NaN       NaN       NaN   \n",
       "\n",
       "              SPREAD  \n",
       "attempt_47  0.151611  \n",
       "attempt_48  0.153696  \n",
       "attempt_44  0.155088  \n",
       "attempt_20  0.146890  \n",
       "attempt_39  0.155019  \n",
       "attempt_6   0.148330  \n",
       "attempt_29  0.154955  \n",
       "attempt_43  0.152239  \n",
       "attempt_40  0.153451  \n",
       "attempt_26  0.147398  \n",
       "attempt_22  0.160680  \n",
       "attempt_9   0.157222  \n",
       "attempt_42  0.159141  \n",
       "attempt_24  0.162986  \n",
       "attempt_45  0.166086  \n",
       "attempt_13  0.169598  \n",
       "attempt_30  0.162823  \n",
       "attempt_27  0.159279  \n",
       "attempt_41  0.155277  \n",
       "attempt_18  0.167729  \n",
       "attempt_10  0.155790  \n",
       "attempt_12  0.163456  \n",
       "attempt_37  0.167548  \n",
       "attempt_11  0.157384  \n",
       "attempt_25  0.164972  \n",
       "attempt_28  0.159257  \n",
       "attempt_21  0.162099  \n",
       "attempt_23  0.171737  \n",
       "attempt_49  0.163570  \n",
       "attempt_14  0.141926  \n",
       "attempt_19  0.162370  \n",
       "attempt_31  0.167990  \n",
       "attempt_8   0.148008  \n",
       "attempt_38  0.173689  \n",
       "attempt_32  0.161720  \n",
       "attempt_36  0.185006  \n",
       "attempt_33  0.149879  \n",
       "attempt_7   0.165801  \n",
       "attempt_46  0.190089  \n",
       "attempt_15  0.231926  \n",
       "attempt_34  0.186733  \n",
       "attempt_35  0.181120  \n",
       "attempt_16       NaN  \n",
       "attempt_17       NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = stats.sort_values(by='RMS_AUC', ascending=False)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed895c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7320508075688772"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum([1 for _ in range(3)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2384d3-c359-4ce5-9df1-9b5c252d938b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85449ab7-874d-45e1-b595-5232e1dcb6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[\"RMS_AUC\"] = np.sqrt((all_results.Ato4l**2 + all_results.hToTauTau**2 + all_results.hChToTauNu**2 + all_results.leptoquark**2)/4)\n",
    "all_results[\"MEAN_AUC\"] = all_results.iloc[:, :4].mean(axis=1)\n",
    "all_results[\"SPREAD\"] = all_results.iloc[:, :4].max(axis=1) - all_results.iloc[:, :4].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b84c48b2-e101-46cf-acf0-69b9ce3e89ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the row if it has any AUC less than 0.79. \n",
    "threshold = 0.79\n",
    "cols = [\"Ato4l\", \"hToTauTau\", \"hChToTauNu\", \"leptoquark\"]\n",
    "all_results = all_results.loc[(all_results[cols] >= threshold).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe5a67d4-5038-466c-be01-c53efb9936f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ato4l</th>\n",
       "      <th>hToTauTau</th>\n",
       "      <th>hChToTauNu</th>\n",
       "      <th>leptoquark</th>\n",
       "      <th>RMS_AUC</th>\n",
       "      <th>MEAN_AUC</th>\n",
       "      <th>SPREAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attempt30_iter_3</th>\n",
       "      <td>0.904281</td>\n",
       "      <td>0.795604</td>\n",
       "      <td>0.931567</td>\n",
       "      <td>0.900733</td>\n",
       "      <td>0.884569</td>\n",
       "      <td>0.883046</td>\n",
       "      <td>0.135963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt20_iter_7</th>\n",
       "      <td>0.924522</td>\n",
       "      <td>0.799560</td>\n",
       "      <td>0.898655</td>\n",
       "      <td>0.881706</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.876111</td>\n",
       "      <td>0.124962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt26_iter_1</th>\n",
       "      <td>0.909648</td>\n",
       "      <td>0.806666</td>\n",
       "      <td>0.900492</td>\n",
       "      <td>0.888728</td>\n",
       "      <td>0.877339</td>\n",
       "      <td>0.876384</td>\n",
       "      <td>0.102982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt9_iter_6</th>\n",
       "      <td>0.922363</td>\n",
       "      <td>0.799251</td>\n",
       "      <td>0.905183</td>\n",
       "      <td>0.874381</td>\n",
       "      <td>0.876563</td>\n",
       "      <td>0.875294</td>\n",
       "      <td>0.123113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt37_iter_3</th>\n",
       "      <td>0.925020</td>\n",
       "      <td>0.795849</td>\n",
       "      <td>0.895894</td>\n",
       "      <td>0.880595</td>\n",
       "      <td>0.875659</td>\n",
       "      <td>0.874340</td>\n",
       "      <td>0.129172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt43_iter_6</th>\n",
       "      <td>0.922287</td>\n",
       "      <td>0.791996</td>\n",
       "      <td>0.891548</td>\n",
       "      <td>0.874944</td>\n",
       "      <td>0.871530</td>\n",
       "      <td>0.870194</td>\n",
       "      <td>0.130291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt43_iter_0</th>\n",
       "      <td>0.921156</td>\n",
       "      <td>0.790336</td>\n",
       "      <td>0.891824</td>\n",
       "      <td>0.873129</td>\n",
       "      <td>0.870469</td>\n",
       "      <td>0.869111</td>\n",
       "      <td>0.130819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt35_iter_1</th>\n",
       "      <td>0.919565</td>\n",
       "      <td>0.793042</td>\n",
       "      <td>0.884439</td>\n",
       "      <td>0.875767</td>\n",
       "      <td>0.869442</td>\n",
       "      <td>0.868203</td>\n",
       "      <td>0.126523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt19_iter_0</th>\n",
       "      <td>0.922172</td>\n",
       "      <td>0.799977</td>\n",
       "      <td>0.880096</td>\n",
       "      <td>0.867896</td>\n",
       "      <td>0.868645</td>\n",
       "      <td>0.867535</td>\n",
       "      <td>0.122195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt18_iter_9</th>\n",
       "      <td>0.917649</td>\n",
       "      <td>0.795939</td>\n",
       "      <td>0.883224</td>\n",
       "      <td>0.868417</td>\n",
       "      <td>0.867443</td>\n",
       "      <td>0.866307</td>\n",
       "      <td>0.121711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt43_iter_1</th>\n",
       "      <td>0.916850</td>\n",
       "      <td>0.791937</td>\n",
       "      <td>0.877026</td>\n",
       "      <td>0.864847</td>\n",
       "      <td>0.863845</td>\n",
       "      <td>0.862665</td>\n",
       "      <td>0.124912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt40_iter_7</th>\n",
       "      <td>0.885304</td>\n",
       "      <td>0.792607</td>\n",
       "      <td>0.864640</td>\n",
       "      <td>0.862436</td>\n",
       "      <td>0.851966</td>\n",
       "      <td>0.851247</td>\n",
       "      <td>0.092697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Ato4l  hToTauTau  hChToTauNu  leptoquark   RMS_AUC  \\\n",
       "Attempt30_iter_3  0.904281   0.795604    0.931567    0.900733  0.884569   \n",
       "Attempt20_iter_7  0.924522   0.799560    0.898655    0.881706  0.877358   \n",
       "Attempt26_iter_1  0.909648   0.806666    0.900492    0.888728  0.877339   \n",
       "Attempt9_iter_6   0.922363   0.799251    0.905183    0.874381  0.876563   \n",
       "Attempt37_iter_3  0.925020   0.795849    0.895894    0.880595  0.875659   \n",
       "Attempt43_iter_6  0.922287   0.791996    0.891548    0.874944  0.871530   \n",
       "Attempt43_iter_0  0.921156   0.790336    0.891824    0.873129  0.870469   \n",
       "Attempt35_iter_1  0.919565   0.793042    0.884439    0.875767  0.869442   \n",
       "Attempt19_iter_0  0.922172   0.799977    0.880096    0.867896  0.868645   \n",
       "Attempt18_iter_9  0.917649   0.795939    0.883224    0.868417  0.867443   \n",
       "Attempt43_iter_1  0.916850   0.791937    0.877026    0.864847  0.863845   \n",
       "Attempt40_iter_7  0.885304   0.792607    0.864640    0.862436  0.851966   \n",
       "\n",
       "                  MEAN_AUC    SPREAD  \n",
       "Attempt30_iter_3  0.883046  0.135963  \n",
       "Attempt20_iter_7  0.876111  0.124962  \n",
       "Attempt26_iter_1  0.876384  0.102982  \n",
       "Attempt9_iter_6   0.875294  0.123113  \n",
       "Attempt37_iter_3  0.874340  0.129172  \n",
       "Attempt43_iter_6  0.870194  0.130291  \n",
       "Attempt43_iter_0  0.869111  0.130819  \n",
       "Attempt35_iter_1  0.868203  0.126523  \n",
       "Attempt19_iter_0  0.867535  0.122195  \n",
       "Attempt18_iter_9  0.866307  0.121711  \n",
       "Attempt43_iter_1  0.862665  0.124912  \n",
       "Attempt40_iter_7  0.851247  0.092697  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = all_results.sort_values(by='RMS_AUC', ascending=False)\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "026add9f-ea8b-4b9a-888d-f2015beff9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ato4l</th>\n",
       "      <th>hToTauTau</th>\n",
       "      <th>hChToTauNu</th>\n",
       "      <th>leptoquark</th>\n",
       "      <th>RMS_AUC</th>\n",
       "      <th>MEAN_AUC</th>\n",
       "      <th>SPREAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attempt30_iter_3</th>\n",
       "      <td>0.904281</td>\n",
       "      <td>0.795604</td>\n",
       "      <td>0.931567</td>\n",
       "      <td>0.900733</td>\n",
       "      <td>1.769137</td>\n",
       "      <td>0.883046</td>\n",
       "      <td>0.135963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt26_iter_1</th>\n",
       "      <td>0.909648</td>\n",
       "      <td>0.806666</td>\n",
       "      <td>0.900492</td>\n",
       "      <td>0.888728</td>\n",
       "      <td>1.754678</td>\n",
       "      <td>0.876384</td>\n",
       "      <td>0.102982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt20_iter_7</th>\n",
       "      <td>0.924522</td>\n",
       "      <td>0.799560</td>\n",
       "      <td>0.898655</td>\n",
       "      <td>0.881706</td>\n",
       "      <td>1.754715</td>\n",
       "      <td>0.876111</td>\n",
       "      <td>0.124962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt9_iter_6</th>\n",
       "      <td>0.922363</td>\n",
       "      <td>0.799251</td>\n",
       "      <td>0.905183</td>\n",
       "      <td>0.874381</td>\n",
       "      <td>1.753127</td>\n",
       "      <td>0.875294</td>\n",
       "      <td>0.123113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt37_iter_3</th>\n",
       "      <td>0.925020</td>\n",
       "      <td>0.795849</td>\n",
       "      <td>0.895894</td>\n",
       "      <td>0.880595</td>\n",
       "      <td>1.751317</td>\n",
       "      <td>0.874340</td>\n",
       "      <td>0.129172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt43_iter_6</th>\n",
       "      <td>0.922287</td>\n",
       "      <td>0.791996</td>\n",
       "      <td>0.891548</td>\n",
       "      <td>0.874944</td>\n",
       "      <td>1.743059</td>\n",
       "      <td>0.870194</td>\n",
       "      <td>0.130291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt43_iter_0</th>\n",
       "      <td>0.921156</td>\n",
       "      <td>0.790336</td>\n",
       "      <td>0.891824</td>\n",
       "      <td>0.873129</td>\n",
       "      <td>1.740938</td>\n",
       "      <td>0.869111</td>\n",
       "      <td>0.130819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt35_iter_1</th>\n",
       "      <td>0.919565</td>\n",
       "      <td>0.793042</td>\n",
       "      <td>0.884439</td>\n",
       "      <td>0.875767</td>\n",
       "      <td>1.738884</td>\n",
       "      <td>0.868203</td>\n",
       "      <td>0.126523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt19_iter_0</th>\n",
       "      <td>0.922172</td>\n",
       "      <td>0.799977</td>\n",
       "      <td>0.880096</td>\n",
       "      <td>0.867896</td>\n",
       "      <td>1.737290</td>\n",
       "      <td>0.867535</td>\n",
       "      <td>0.122195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt18_iter_9</th>\n",
       "      <td>0.917649</td>\n",
       "      <td>0.795939</td>\n",
       "      <td>0.883224</td>\n",
       "      <td>0.868417</td>\n",
       "      <td>1.734887</td>\n",
       "      <td>0.866307</td>\n",
       "      <td>0.121711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt43_iter_1</th>\n",
       "      <td>0.916850</td>\n",
       "      <td>0.791937</td>\n",
       "      <td>0.877026</td>\n",
       "      <td>0.864847</td>\n",
       "      <td>1.727690</td>\n",
       "      <td>0.862665</td>\n",
       "      <td>0.124912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt40_iter_7</th>\n",
       "      <td>0.885304</td>\n",
       "      <td>0.792607</td>\n",
       "      <td>0.864640</td>\n",
       "      <td>0.862436</td>\n",
       "      <td>1.703933</td>\n",
       "      <td>0.851247</td>\n",
       "      <td>0.092697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Ato4l  hToTauTau  hChToTauNu  leptoquark   RMS_AUC  \\\n",
       "Attempt30_iter_3  0.904281   0.795604    0.931567    0.900733  1.769137   \n",
       "Attempt26_iter_1  0.909648   0.806666    0.900492    0.888728  1.754678   \n",
       "Attempt20_iter_7  0.924522   0.799560    0.898655    0.881706  1.754715   \n",
       "Attempt9_iter_6   0.922363   0.799251    0.905183    0.874381  1.753127   \n",
       "Attempt37_iter_3  0.925020   0.795849    0.895894    0.880595  1.751317   \n",
       "Attempt43_iter_6  0.922287   0.791996    0.891548    0.874944  1.743059   \n",
       "Attempt43_iter_0  0.921156   0.790336    0.891824    0.873129  1.740938   \n",
       "Attempt35_iter_1  0.919565   0.793042    0.884439    0.875767  1.738884   \n",
       "Attempt19_iter_0  0.922172   0.799977    0.880096    0.867896  1.737290   \n",
       "Attempt18_iter_9  0.917649   0.795939    0.883224    0.868417  1.734887   \n",
       "Attempt43_iter_1  0.916850   0.791937    0.877026    0.864847  1.727690   \n",
       "Attempt40_iter_7  0.885304   0.792607    0.864640    0.862436  1.703933   \n",
       "\n",
       "                  MEAN_AUC    SPREAD  \n",
       "Attempt30_iter_3  0.883046  0.135963  \n",
       "Attempt26_iter_1  0.876384  0.102982  \n",
       "Attempt20_iter_7  0.876111  0.124962  \n",
       "Attempt9_iter_6   0.875294  0.123113  \n",
       "Attempt37_iter_3  0.874340  0.129172  \n",
       "Attempt43_iter_6  0.870194  0.130291  \n",
       "Attempt43_iter_0  0.869111  0.130819  \n",
       "Attempt35_iter_1  0.868203  0.126523  \n",
       "Attempt19_iter_0  0.867535  0.122195  \n",
       "Attempt18_iter_9  0.866307  0.121711  \n",
       "Attempt43_iter_1  0.862665  0.124912  \n",
       "Attempt40_iter_7  0.851247  0.092697  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = all_results.sort_values(by=\"MEAN_AUC\", ascending = False)\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3602c69c-3ae7-4dc8-b65a-1888d53efd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ato4l</th>\n",
       "      <th>hToTauTau</th>\n",
       "      <th>hChToTauNu</th>\n",
       "      <th>leptoquark</th>\n",
       "      <th>RMS_AUC</th>\n",
       "      <th>MEAN_AUC</th>\n",
       "      <th>SPREAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attempt8_iter_7</th>\n",
       "      <td>0.810077</td>\n",
       "      <td>0.730131</td>\n",
       "      <td>0.800311</td>\n",
       "      <td>0.745802</td>\n",
       "      <td>1.544680</td>\n",
       "      <td>0.771580</td>\n",
       "      <td>0.079947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt14_iter_2</th>\n",
       "      <td>0.719395</td>\n",
       "      <td>0.729189</td>\n",
       "      <td>0.806499</td>\n",
       "      <td>0.776158</td>\n",
       "      <td>1.517270</td>\n",
       "      <td>0.757810</td>\n",
       "      <td>0.087104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt40_iter_7</th>\n",
       "      <td>0.885304</td>\n",
       "      <td>0.792607</td>\n",
       "      <td>0.864640</td>\n",
       "      <td>0.862436</td>\n",
       "      <td>1.703933</td>\n",
       "      <td>0.851247</td>\n",
       "      <td>0.092697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt32_iter_3</th>\n",
       "      <td>0.850447</td>\n",
       "      <td>0.754521</td>\n",
       "      <td>0.845967</td>\n",
       "      <td>0.821162</td>\n",
       "      <td>1.637843</td>\n",
       "      <td>0.818024</td>\n",
       "      <td>0.095926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt8_iter_5</th>\n",
       "      <td>0.883276</td>\n",
       "      <td>0.780738</td>\n",
       "      <td>0.880568</td>\n",
       "      <td>0.848191</td>\n",
       "      <td>1.698398</td>\n",
       "      <td>0.848193</td>\n",
       "      <td>0.102538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt37_iter_8</th>\n",
       "      <td>0.829493</td>\n",
       "      <td>0.571376</td>\n",
       "      <td>0.684756</td>\n",
       "      <td>0.667095</td>\n",
       "      <td>1.388681</td>\n",
       "      <td>0.688180</td>\n",
       "      <td>0.258117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt46_iter_3</th>\n",
       "      <td>0.757566</td>\n",
       "      <td>0.493914</td>\n",
       "      <td>0.580576</td>\n",
       "      <td>0.507523</td>\n",
       "      <td>1.188488</td>\n",
       "      <td>0.584895</td>\n",
       "      <td>0.263651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt34_iter_3</th>\n",
       "      <td>0.756485</td>\n",
       "      <td>0.478363</td>\n",
       "      <td>0.491274</td>\n",
       "      <td>0.494872</td>\n",
       "      <td>1.134614</td>\n",
       "      <td>0.555249</td>\n",
       "      <td>0.278121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt35_iter_0</th>\n",
       "      <td>0.684154</td>\n",
       "      <td>0.414690</td>\n",
       "      <td>0.430752</td>\n",
       "      <td>0.403990</td>\n",
       "      <td>0.994379</td>\n",
       "      <td>0.483396</td>\n",
       "      <td>0.280164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attempt32_iter_6</th>\n",
       "      <td>0.688462</td>\n",
       "      <td>0.416453</td>\n",
       "      <td>0.357969</td>\n",
       "      <td>0.327205</td>\n",
       "      <td>0.939477</td>\n",
       "      <td>0.447522</td>\n",
       "      <td>0.361256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Ato4l  hToTauTau  hChToTauNu  leptoquark   RMS_AUC  \\\n",
       "Attempt8_iter_7   0.810077   0.730131    0.800311    0.745802  1.544680   \n",
       "Attempt14_iter_2  0.719395   0.729189    0.806499    0.776158  1.517270   \n",
       "Attempt40_iter_7  0.885304   0.792607    0.864640    0.862436  1.703933   \n",
       "Attempt32_iter_3  0.850447   0.754521    0.845967    0.821162  1.637843   \n",
       "Attempt8_iter_5   0.883276   0.780738    0.880568    0.848191  1.698398   \n",
       "...                    ...        ...         ...         ...       ...   \n",
       "Attempt37_iter_8  0.829493   0.571376    0.684756    0.667095  1.388681   \n",
       "Attempt46_iter_3  0.757566   0.493914    0.580576    0.507523  1.188488   \n",
       "Attempt34_iter_3  0.756485   0.478363    0.491274    0.494872  1.134614   \n",
       "Attempt35_iter_0  0.684154   0.414690    0.430752    0.403990  0.994379   \n",
       "Attempt32_iter_6  0.688462   0.416453    0.357969    0.327205  0.939477   \n",
       "\n",
       "                  MEAN_AUC    SPREAD  \n",
       "Attempt8_iter_7   0.771580  0.079947  \n",
       "Attempt14_iter_2  0.757810  0.087104  \n",
       "Attempt40_iter_7  0.851247  0.092697  \n",
       "Attempt32_iter_3  0.818024  0.095926  \n",
       "Attempt8_iter_5   0.848193  0.102538  \n",
       "...                    ...       ...  \n",
       "Attempt37_iter_8  0.688180  0.258117  \n",
       "Attempt46_iter_3  0.584895  0.263651  \n",
       "Attempt34_iter_3  0.555249  0.278121  \n",
       "Attempt35_iter_0  0.483396  0.280164  \n",
       "Attempt32_iter_6  0.447522  0.361256  \n",
       "\n",
       "[407 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = all_results.sort_values(by='SPREAD')\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee8e18bf-f5bb-446c-9d8d-f480d527038a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot do slice indexing on Index with these indexers [4] of type int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mall_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.12.0/lib/python3.9/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.12.0/lib/python3.9/site-packages/pandas/core/indexing.py:1411\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m   1410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_slice_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getbool_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.12.0/lib/python3.9/site-packages/pandas/core/indexing.py:1443\u001b[0m, in \u001b[0;36m_LocIndexer._get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1442\u001b[0m labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m-> 1443\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m   1446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_slice(indexer, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.12.0/lib/python3.9/site-packages/pandas/core/indexes/base.py:6662\u001b[0m, in \u001b[0;36mIndex.slice_indexer\u001b[0;34m(self, start, end, step)\u001b[0m\n\u001b[1;32m   6618\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslice_indexer\u001b[39m(\n\u001b[1;32m   6619\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   6620\u001b[0m     start: Hashable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   6621\u001b[0m     end: Hashable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   6622\u001b[0m     step: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   6623\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mslice\u001b[39m:\n\u001b[1;32m   6624\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6625\u001b[0m \u001b[38;5;124;03m    Compute the slice indexer for input labels and step.\u001b[39;00m\n\u001b[1;32m   6626\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6660\u001b[0m \u001b[38;5;124;03m    slice(1, 3, None)\u001b[39;00m\n\u001b[1;32m   6661\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6662\u001b[0m     start_slice, end_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_locs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6664\u001b[0m     \u001b[38;5;66;03m# return a slice\u001b[39;00m\n\u001b[1;32m   6665\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(start_slice):\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.12.0/lib/python3.9/site-packages/pandas/core/indexes/base.py:6885\u001b[0m, in \u001b[0;36mIndex.slice_locs\u001b[0;34m(self, start, end, step)\u001b[0m\n\u001b[1;32m   6883\u001b[0m end_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   6884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 6885\u001b[0m     end_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_slice_bound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mright\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end_slice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   6887\u001b[0m     end_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.12.0/lib/python3.9/site-packages/pandas/core/indexes/base.py:6794\u001b[0m, in \u001b[0;36mIndex.get_slice_bound\u001b[0;34m(self, label, side)\u001b[0m\n\u001b[1;32m   6790\u001b[0m original_label \u001b[38;5;241m=\u001b[39m label\n\u001b[1;32m   6792\u001b[0m \u001b[38;5;66;03m# For datetime indices label may be a string that has to be converted\u001b[39;00m\n\u001b[1;32m   6793\u001b[0m \u001b[38;5;66;03m# to datetime boundary according to its resolution.\u001b[39;00m\n\u001b[0;32m-> 6794\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_cast_slice_bound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6796\u001b[0m \u001b[38;5;66;03m# we need to look up the label\u001b[39;00m\n\u001b[1;32m   6797\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.12.0/lib/python3.9/site-packages/pandas/core/indexes/base.py:6727\u001b[0m, in \u001b[0;36mIndex._maybe_cast_slice_bound\u001b[0;34m(self, label, side)\u001b[0m\n\u001b[1;32m   6725\u001b[0m \u001b[38;5;66;03m# reject them, if index does not contain label\u001b[39;00m\n\u001b[1;32m   6726\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (is_float(label) \u001b[38;5;129;01mor\u001b[39;00m is_integer(label)) \u001b[38;5;129;01mand\u001b[39;00m label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m-> 6727\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_invalid_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mslice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m label\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.12.0/lib/python3.9/site-packages/pandas/core/indexes/base.py:4301\u001b[0m, in \u001b[0;36mIndex._raise_invalid_indexer\u001b[0;34m(self, form, key, reraise)\u001b[0m\n\u001b[1;32m   4299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reraise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   4300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreraise\u001b[39;00m\n\u001b[0;32m-> 4301\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot do slice indexing on Index with these indexers [4] of type int"
     ]
    }
   ],
   "source": [
    "all_results.loc[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182753ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data = [leptoquark_data, Ato4l_data, hChToTauNu_data, hToTauTau_data\n",
    "#                , X_train\n",
    "#                , X_test\n",
    "#                ] # Already defined.\n",
    "data_names_tex = [ # latex version\n",
    "                \"Leptoquark\"\n",
    "                , \"$A\\\\rightarrow 4\\ell$\"\n",
    "                , \"$h^{\\pm}\\\\rightarrow\\\\tau \\\\nu$\"\n",
    "                , \"$h^0\\\\rightarrow\\\\tau\\\\tau$\"\n",
    "                , \"Training Set (BG)\" # Background\n",
    "                , \"Test Set (BG)\" # Background\n",
    "                ]\n",
    "\n",
    "anomaly_scores = []\n",
    "for _, dat in data.items():\n",
    "    s = calc_anomaly_dist(dat, just_enc, AD_score_CKL)\n",
    "    anomaly_scores.append(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c285ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot setting for CKL\n",
    "bin_n = 125\n",
    "xlims = (0, 40)\n",
    "ylims = (0, 0.03)\n",
    "bins  = np.linspace(xlims[0], xlims[1], bin_n)\n",
    "xlabel = \"Clipped KL\"\n",
    "\n",
    "\n",
    "# # Investigating around the threshold at 161\n",
    "# ckl_roc_threshold = 161.84\n",
    "# bin_n = 10\n",
    "# l_margin = 10 \n",
    "# r_margin = 300\n",
    "\n",
    "# xlims = ( ckl_roc_threshold - l_margin , ckl_roc_threshold + r_margin)\n",
    "# ylims = (0, 0.01)\n",
    "# bins  = np.linspace(xlims[0], xlims[1], bin_n)\n",
    "# xlabel = \"Clipped KL\"\n",
    "\n",
    "# Plot settings for KL\n",
    "# bin_n = 125\n",
    "# xlims = (0, 40)\n",
    "# ylims = (0, 0.0125)\n",
    "# bins  = np.linspace(0, xlims[1], bin_n)\n",
    "# xlabel = \"KL Divergence\"\n",
    "\n",
    "for i in range(len(data_names_tex)):\n",
    "    dat = anomaly_scores[i]\n",
    "    # print(bin_n)\n",
    "    plt.hist(dat\n",
    "             , bins = bins\n",
    "             , label=data_names_tex[i] # + \" \" + str(bin_n)\n",
    "             , histtype = \"step\"\n",
    "             , density=True\n",
    "             )\n",
    "plt.legend(loc=\"upper right\")\n",
    "# plt.vlines(ckl_roc_threshold, 0, 1)\n",
    "# plt.loglog()\n",
    "# plt.semilogy()\n",
    "# plt.semilogx()\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel(\"Density\")\n",
    "plt.grid()\n",
    "plt.ylim(ylims)\n",
    "plt.xlim(xlims)\n",
    "plt.title(\"Anomaly Score Distribution Across Datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b7acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
