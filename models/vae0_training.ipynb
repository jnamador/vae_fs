{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b693cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 12:30:35.119732: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-09 12:30:36.524084: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\" # on NERSC filelocking is not allowed\n",
    "import h5py\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "import tensorflow as tf\n",
    "# Make notebook run on other GPUS. GPT's solution ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(gpus[0], 'GPU')  # change 1 to 0, 2, 3 as needed\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "import sys\n",
    "# Path to dir model.py lives in -------\n",
    "# NOTE: This needs to be modified to where your repo lives, path to /repo/path/VAE_FS/models/\n",
    "# If the jupyter notebook kernel is running from VAE_FS/models/ the\n",
    "# line below is not needed\n",
    "sys.path.append('/global/homes/j/jananinf/projs/VAE_FS/models/')\n",
    "\n",
    "# import the custom models and functions\n",
    "from models import VAE_Model, Qmake_encoder_set_weights, Qmake_decoder_set_weights\n",
    "# in VAE_0 we are using the beta cyclical annealing from Kenny's repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9774118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from preprocessed_SNL_data.h5\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "home_path = \"/global/cfs/cdirs/m2616/jananinf/projsIO/VAE_FS/\" # Updated to NERSC\n",
    "file_path = home_path + \"preprocessed_SNL_data.h5\"\n",
    "with h5py.File(file_path, 'r') as hf:           # Shapes:\n",
    "    X_train = hf['X_train'][:]                  # (3200000, 57)\n",
    "    X_test  = hf['X_test'][:]                   # (800000,  57)\n",
    "    Ato4l_data  = hf['Ato4l_data'][:]           # (55969,   57) Signal data \n",
    "    hToTauTau_data  = hf['hToTauTau_data'][:]   # (691283,  57) \"\"\n",
    "    hChToTauNu_data  = hf['hChToTauNu_data'][:] # (760272,  57) \"\"\n",
    "    leptoquark_data = hf['leptoquark_data'][:]  # (340544,  57) \"\"\n",
    "    print(\"Data loaded from preprocessed_SNL_data.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9877d36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 57)]         0           []                               \n",
      "                                                                                                  \n",
      " enc_dense1 (Dense)             (None, 32)           1856        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " enc_Lrelu1 (LeakyReLU)         (None, 32)           0           ['enc_dense1[0][0]']             \n",
      "                                                                                                  \n",
      " enc_dense2 (Dense)             (None, 16)           528         ['enc_Lrelu1[0][0]']             \n",
      "                                                                                                  \n",
      " enc_Lrelu2 (LeakyReLU)         (None, 16)           0           ['enc_dense2[0][0]']             \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 3)            51          ['enc_Lrelu2[0][0]']             \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 3)            51          ['enc_Lrelu2[0][0]']             \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 3)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,486\n",
      "Trainable params: 2,486\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 12:30:41.937835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 37066 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "INPUT_SZ = 57\n",
    "H1_SZ = 32\n",
    "H2_SZ = 16\n",
    "LATENT_SZ = 3\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 16384\n",
    "STOP_PATIENCE = 15\n",
    "LR_PATIENCE = 10\n",
    "\n",
    "enc = Qmake_encoder_set_weights(INPUT_SZ, H1_SZ, H2_SZ, LATENT_SZ)\n",
    "enc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6fd932e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                64        \n",
      "                                                                 \n",
      " dec_Lrelu3 (LeakyReLU)      (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dec_Lrelu4 (LeakyReLU)      (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 57)                1881      \n",
      "                                                                 \n",
      " dec_Lrelu5 (LeakyReLU)      (None, 57)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,489\n",
      "Trainable params: 2,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dec = Qmake_decoder_set_weights(INPUT_SZ, H1_SZ, H2_SZ, LATENT_SZ)\n",
    "dec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "453cfecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = X_train.shape[0] // BATCH_SIZE\n",
    "vae = VAE_Model(enc, dec, steps_per_epoch=steps_per_epoch, cycle_length=10, min_beta=0.1, max_beta=0.8)\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001, clipnorm=1000)\n",
    "vae.compile(optimizer=opt) # Not sure what weighted_mse is doing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fd0d075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like early_stopping is needed for val_loss\n",
    "early_stopping = EarlyStopping(patience=STOP_PATIENCE, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=LR_PATIENCE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff3710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ITERATION 0 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3437 - reconstruction_loss: 0.3403 - kl_loss: 0.0080 - beta: 0.2870 - val_loss: 0.8567 - val_reconstruction_loss: 0.8368 - val_kl_loss: 0.0199 - val_beta: 0.2870 - lr: 1.2500e-05\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3209 - reconstruction_loss: 0.3099 - kl_loss: 0.0107 - beta: 0.3434 - val_loss: 0.7957 - val_reconstruction_loss: 0.7699 - val_kl_loss: 0.0258 - val_beta: 0.3434 - lr: 1.2500e-05\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2992 - reconstruction_loss: 0.2818 - kl_loss: 0.0135 - beta: 0.3998 - val_loss: 0.7349 - val_reconstruction_loss: 0.7034 - val_kl_loss: 0.0315 - val_beta: 0.3998 - lr: 1.2500e-05\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2794 - reconstruction_loss: 0.2547 - kl_loss: 0.0163 - beta: 0.4561 - val_loss: 0.6746 - val_reconstruction_loss: 0.6382 - val_kl_loss: 0.0364 - val_beta: 0.4561 - lr: 1.2500e-05\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2521 - reconstruction_loss: 0.2293 - kl_loss: 0.0186 - beta: 0.5125 - val_loss: 0.6106 - val_reconstruction_loss: 0.5700 - val_kl_loss: 0.0405 - val_beta: 0.5125 - lr: 1.2500e-05\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2352 - reconstruction_loss: 0.2043 - kl_loss: 0.0201 - beta: 0.5688 - val_loss: 0.5504 - val_reconstruction_loss: 0.5070 - val_kl_loss: 0.0434 - val_beta: 0.5688 - lr: 1.2500e-05\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2109 - reconstruction_loss: 0.1795 - kl_loss: 0.0209 - beta: 0.6252 - val_loss: 0.4835 - val_reconstruction_loss: 0.4382 - val_kl_loss: 0.0453 - val_beta: 0.6252 - lr: 1.2500e-05\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.1779 - reconstruction_loss: 0.1551 - kl_loss: 0.0213 - beta: 0.6816 - val_loss: 0.4198 - val_reconstruction_loss: 0.3732 - val_kl_loss: 0.0465 - val_beta: 0.6816 - lr: 1.2500e-05\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1539 - reconstruction_loss: 0.1303 - kl_loss: 0.0212 - beta: 0.7379 - val_loss: 0.3543 - val_reconstruction_loss: 0.3070 - val_kl_loss: 0.0474 - val_beta: 0.7379 - lr: 1.2500e-05\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1288 - reconstruction_loss: 0.1059 - kl_loss: 0.0211 - beta: 0.7943 - val_loss: 0.2891 - val_reconstruction_loss: 0.2409 - val_kl_loss: 0.0481 - val_beta: 0.7943 - lr: 1.2500e-05\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3103 - reconstruction_loss: 0.3641 - kl_loss: 0.0055 - beta: 0.1506 - val_loss: 1.0010 - val_reconstruction_loss: 0.9902 - val_kl_loss: 0.0109 - val_beta: 0.1506 - lr: 1.2500e-05\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3745 - reconstruction_loss: 0.3621 - kl_loss: 0.0066 - beta: 0.2070 - val_loss: 0.9404 - val_reconstruction_loss: 0.9227 - val_kl_loss: 0.0177 - val_beta: 0.2070 - lr: 1.2500e-05\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3632 - reconstruction_loss: 0.3333 - kl_loss: 0.0105 - beta: 0.2633 - val_loss: 0.8789 - val_reconstruction_loss: 0.8537 - val_kl_loss: 0.0252 - val_beta: 0.2633 - lr: 1.2500e-05\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3319 - reconstruction_loss: 0.3042 - kl_loss: 0.0149 - beta: 0.3197 - val_loss: 0.8205 - val_reconstruction_loss: 0.7882 - val_kl_loss: 0.0323 - val_beta: 0.3197 - lr: 1.2500e-05\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2931 - reconstruction_loss: 0.2766 - kl_loss: 0.0185 - beta: 0.3761 - val_loss: 0.7574 - val_reconstruction_loss: 0.7193 - val_kl_loss: 0.0382 - val_beta: 0.3761 - lr: 1.2500e-05\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2778 - reconstruction_loss: 0.2525 - kl_loss: 0.0212 - beta: 0.4324 - val_loss: 0.6966 - val_reconstruction_loss: 0.6539 - val_kl_loss: 0.0427 - val_beta: 0.4324 - lr: 1.2500e-05\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2523 - reconstruction_loss: 0.2289 - kl_loss: 0.0230 - beta: 0.4888 - val_loss: 0.6351 - val_reconstruction_loss: 0.5892 - val_kl_loss: 0.0459 - val_beta: 0.4888 - lr: 1.2500e-05\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2298 - reconstruction_loss: 0.2060 - kl_loss: 0.0235 - beta: 0.5451 - val_loss: 0.5739 - val_reconstruction_loss: 0.5258 - val_kl_loss: 0.0481 - val_beta: 0.5451 - lr: 1.2500e-05\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2055 - reconstruction_loss: 0.1836 - kl_loss: 0.0236 - beta: 0.6015 - val_loss: 0.5104 - val_reconstruction_loss: 0.4615 - val_kl_loss: 0.0489 - val_beta: 0.6015 - lr: 1.2500e-05\n",
      "Epoch 20/100\n",
      "154/157 [============================>.] - ETA: 0s - loss: 0.1991 - reconstruction_loss: 0.1617 - kl_loss: 0.0228 - beta: 0.6568\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.1987 - reconstruction_loss: 0.1612 - kl_loss: 0.0228 - beta: 0.6579 - val_loss: 0.4463 - val_reconstruction_loss: 0.3969 - val_kl_loss: 0.0494 - val_beta: 0.6579 - lr: 1.2500e-05\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1675 - reconstruction_loss: 0.1375 - kl_loss: 0.0226 - beta: 0.7142 - val_loss: 0.3837 - val_reconstruction_loss: 0.3326 - val_kl_loss: 0.0511 - val_beta: 0.7142 - lr: 6.2500e-06\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1346 - reconstruction_loss: 0.1128 - kl_loss: 0.0227 - beta: 0.7706 - val_loss: 0.3181 - val_reconstruction_loss: 0.2657 - val_kl_loss: 0.0524 - val_beta: 0.7706 - lr: 6.2500e-06\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1586 - reconstruction_loss: 0.2362 - kl_loss: 0.0131 - beta: 0.1269 - val_loss: 1.0193 - val_reconstruction_loss: 1.0104 - val_kl_loss: 0.0089 - val_beta: 0.1269 - lr: 6.2500e-06\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3797 - reconstruction_loss: 0.3684 - kl_loss: 0.0051 - beta: 0.1833 - val_loss: 0.9585 - val_reconstruction_loss: 0.9441 - val_kl_loss: 0.0144 - val_beta: 0.1833 - lr: 6.2500e-06\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3689 - reconstruction_loss: 0.3398 - kl_loss: 0.0080 - beta: 0.2396 - val_loss: 0.8988 - val_reconstruction_loss: 0.8787 - val_kl_loss: 0.0201 - val_beta: 0.2396 - lr: 6.2500e-06\n",
      "SAVING ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "TRAINING ITERATION 1 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3537 - reconstruction_loss: 0.3317 - kl_loss: 0.0073 - beta: 0.2960 - val_loss: 0.8428 - val_reconstruction_loss: 0.8236 - val_kl_loss: 0.0192 - val_beta: 0.2960 - lr: 6.2500e-06\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3285 - reconstruction_loss: 0.3040 - kl_loss: 0.0093 - beta: 0.3524 - val_loss: 0.7797 - val_reconstruction_loss: 0.7555 - val_kl_loss: 0.0241 - val_beta: 0.3524 - lr: 6.2500e-06\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2937 - reconstruction_loss: 0.2768 - kl_loss: 0.0115 - beta: 0.4087 - val_loss: 0.7178 - val_reconstruction_loss: 0.6888 - val_kl_loss: 0.0290 - val_beta: 0.4087 - lr: 6.2500e-06\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2859 - reconstruction_loss: 0.2511 - kl_loss: 0.0137 - beta: 0.4651 - val_loss: 0.6584 - val_reconstruction_loss: 0.6247 - val_kl_loss: 0.0338 - val_beta: 0.4651 - lr: 6.2500e-06\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2513 - reconstruction_loss: 0.2254 - kl_loss: 0.0157 - beta: 0.5214 - val_loss: 0.5943 - val_reconstruction_loss: 0.5564 - val_kl_loss: 0.0379 - val_beta: 0.5214 - lr: 6.2500e-06\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2256 - reconstruction_loss: 0.2000 - kl_loss: 0.0176 - beta: 0.5778 - val_loss: 0.5344 - val_reconstruction_loss: 0.4927 - val_kl_loss: 0.0417 - val_beta: 0.5778 - lr: 6.2500e-06\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2093 - reconstruction_loss: 0.1755 - kl_loss: 0.0189 - beta: 0.6342 - val_loss: 0.4705 - val_reconstruction_loss: 0.4259 - val_kl_loss: 0.0446 - val_beta: 0.6342 - lr: 6.2500e-06\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1770 - reconstruction_loss: 0.1505 - kl_loss: 0.0200 - beta: 0.6905 - val_loss: 0.4075 - val_reconstruction_loss: 0.3605 - val_kl_loss: 0.0470 - val_beta: 0.6905 - lr: 6.2500e-06\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.1500 - reconstruction_loss: 0.1254 - kl_loss: 0.0205 - beta: 0.7469 - val_loss: 0.3446 - val_reconstruction_loss: 0.2959 - val_kl_loss: 0.0488 - val_beta: 0.7469 - lr: 6.2500e-06\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1286 - reconstruction_loss: 0.1194 - kl_loss: 0.0200 - beta: 0.1032 - val_loss: 1.0526 - val_reconstruction_loss: 1.0461 - val_kl_loss: 0.0065 - val_beta: 0.1032 - lr: 6.2500e-06\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.4077 - reconstruction_loss: 0.3892 - kl_loss: 0.0037 - beta: 0.1596 - val_loss: 0.9899 - val_reconstruction_loss: 0.9788 - val_kl_loss: 0.0111 - val_beta: 0.1596 - lr: 6.2500e-06\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3768 - reconstruction_loss: 0.3590 - kl_loss: 0.0060 - beta: 0.2160 - val_loss: 0.9272 - val_reconstruction_loss: 0.9109 - val_kl_loss: 0.0163 - val_beta: 0.2160 - lr: 6.2500e-06\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3356 - reconstruction_loss: 0.3308 - kl_loss: 0.0087 - beta: 0.2723 - val_loss: 0.8681 - val_reconstruction_loss: 0.8460 - val_kl_loss: 0.0221 - val_beta: 0.2723 - lr: 6.2500e-06\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3134 - reconstruction_loss: 0.3037 - kl_loss: 0.0116 - beta: 0.3287 - val_loss: 0.8069 - val_reconstruction_loss: 0.7790 - val_kl_loss: 0.0278 - val_beta: 0.3287 - lr: 6.2500e-06\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3005 - reconstruction_loss: 0.2778 - kl_loss: 0.0145 - beta: 0.3850 - val_loss: 0.7433 - val_reconstruction_loss: 0.7097 - val_kl_loss: 0.0336 - val_beta: 0.3850 - lr: 6.2500e-06\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2765 - reconstruction_loss: 0.2526 - kl_loss: 0.0172 - beta: 0.4414 - val_loss: 0.6811 - val_reconstruction_loss: 0.6425 - val_kl_loss: 0.0387 - val_beta: 0.4414 - lr: 6.2500e-06\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2480 - reconstruction_loss: 0.2285 - kl_loss: 0.0195 - beta: 0.4977 - val_loss: 0.6251 - val_reconstruction_loss: 0.5821 - val_kl_loss: 0.0430 - val_beta: 0.4977 - lr: 6.2500e-06\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2334 - reconstruction_loss: 0.2043 - kl_loss: 0.0211 - beta: 0.5541 - val_loss: 0.5615 - val_reconstruction_loss: 0.5153 - val_kl_loss: 0.0463 - val_beta: 0.5541 - lr: 6.2500e-06\n",
      "Epoch 19/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.2065 - reconstruction_loss: 0.1807 - kl_loss: 0.0221 - beta: 0.6101\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2065 - reconstruction_loss: 0.1810 - kl_loss: 0.0223 - beta: 0.6105 - val_loss: 0.4998 - val_reconstruction_loss: 0.4512 - val_kl_loss: 0.0487 - val_beta: 0.6105 - lr: 6.2500e-06\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1784 - reconstruction_loss: 0.1566 - kl_loss: 0.0231 - beta: 0.6668 - val_loss: 0.4375 - val_reconstruction_loss: 0.3860 - val_kl_loss: 0.0515 - val_beta: 0.6668 - lr: 3.1250e-06\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1645 - reconstruction_loss: 0.1330 - kl_loss: 0.0242 - beta: 0.7232 - val_loss: 0.3746 - val_reconstruction_loss: 0.3206 - val_kl_loss: 0.0540 - val_beta: 0.7232 - lr: 3.1250e-06\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1353 - reconstruction_loss: 0.1086 - kl_loss: 0.0248 - beta: 0.7795 - val_loss: 0.3119 - val_reconstruction_loss: 0.2557 - val_kl_loss: 0.0562 - val_beta: 0.7795 - lr: 3.1250e-06\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1948 - reconstruction_loss: 0.2834 - kl_loss: 0.0115 - beta: 0.1359 - val_loss: 1.0131 - val_reconstruction_loss: 1.0031 - val_kl_loss: 0.0100 - val_beta: 0.1359 - lr: 3.1250e-06\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3777 - reconstruction_loss: 0.3646 - kl_loss: 0.0056 - beta: 0.1923 - val_loss: 0.9528 - val_reconstruction_loss: 0.9380 - val_kl_loss: 0.0148 - val_beta: 0.1923 - lr: 3.1250e-06\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3577 - reconstruction_loss: 0.3378 - kl_loss: 0.0080 - beta: 0.2486 - val_loss: 0.8876 - val_reconstruction_loss: 0.8676 - val_kl_loss: 0.0199 - val_beta: 0.2486 - lr: 3.1250e-06\n",
      "Epoch 26/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3273 - reconstruction_loss: 0.3122 - kl_loss: 0.0106 - beta: 0.3050 - val_loss: 0.8288 - val_reconstruction_loss: 0.8037 - val_kl_loss: 0.0251 - val_beta: 0.3050 - lr: 3.1250e-06\n",
      "Epoch 27/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3158 - reconstruction_loss: 0.2868 - kl_loss: 0.0130 - beta: 0.3613 - val_loss: 0.7702 - val_reconstruction_loss: 0.7401 - val_kl_loss: 0.0301 - val_beta: 0.3613 - lr: 3.1250e-06\n",
      "Epoch 28/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2781 - reconstruction_loss: 0.2618 - kl_loss: 0.0157 - beta: 0.4177 - val_loss: 0.7058 - val_reconstruction_loss: 0.6707 - val_kl_loss: 0.0351 - val_beta: 0.4177 - lr: 3.1250e-06\n",
      "Epoch 29/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2634 - reconstruction_loss: 0.2379 - kl_loss: 0.0182 - beta: 0.4741 - val_loss: 0.6466 - val_reconstruction_loss: 0.6069 - val_kl_loss: 0.0396 - val_beta: 0.4741 - lr: 3.1250e-06\n",
      "Epoch 30/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2387 - reconstruction_loss: 0.2135 - kl_loss: 0.0202 - beta: 0.5304 - val_loss: 0.5867 - val_reconstruction_loss: 0.5427 - val_kl_loss: 0.0440 - val_beta: 0.5304 - lr: 3.1250e-06\n",
      "Epoch 31/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2351 - reconstruction_loss: 0.1895 - kl_loss: 0.0220 - beta: 0.5868 - val_loss: 0.5259 - val_reconstruction_loss: 0.4780 - val_kl_loss: 0.0479 - val_beta: 0.5868 - lr: 3.1250e-06\n",
      "Epoch 32/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1919 - reconstruction_loss: 0.1657 - kl_loss: 0.0234 - beta: 0.6428\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1919 - reconstruction_loss: 0.1655 - kl_loss: 0.0235 - beta: 0.6431 - val_loss: 0.4649 - val_reconstruction_loss: 0.4134 - val_kl_loss: 0.0514 - val_beta: 0.6431 - lr: 3.1250e-06\n",
      "Epoch 33/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1711 - reconstruction_loss: 0.1414 - kl_loss: 0.0247 - beta: 0.6995 - val_loss: 0.4021 - val_reconstruction_loss: 0.3469 - val_kl_loss: 0.0552 - val_beta: 0.6995 - lr: 1.5625e-06\n",
      "Epoch 34/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1430 - reconstruction_loss: 0.1174 - kl_loss: 0.0263 - beta: 0.7558 - val_loss: 0.3409 - val_reconstruction_loss: 0.2823 - val_kl_loss: 0.0586 - val_beta: 0.7558 - lr: 1.5625e-06\n",
      "Epoch 35/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1382 - reconstruction_loss: 0.1577 - kl_loss: 0.0217 - beta: 0.1122 - val_loss: 1.0365 - val_reconstruction_loss: 1.0279 - val_kl_loss: 0.0086 - val_beta: 0.1122 - lr: 1.5625e-06\n",
      "Epoch 36/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3802 - reconstruction_loss: 0.3716 - kl_loss: 0.0050 - beta: 0.1686 - val_loss: 0.9722 - val_reconstruction_loss: 0.9590 - val_kl_loss: 0.0132 - val_beta: 0.1686 - lr: 1.5625e-06\n",
      "Epoch 37/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3652 - reconstruction_loss: 0.3464 - kl_loss: 0.0072 - beta: 0.2249 - val_loss: 0.9138 - val_reconstruction_loss: 0.8959 - val_kl_loss: 0.0179 - val_beta: 0.2249 - lr: 1.5625e-06\n",
      "SAVING ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "TRAINING ITERATION 2 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3346 - reconstruction_loss: 0.3267 - kl_loss: 0.0082 - beta: 0.2813 - val_loss: 0.8515 - val_reconstruction_loss: 0.8309 - val_kl_loss: 0.0206 - val_beta: 0.2813 - lr: 1.5625e-06\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3169 - reconstruction_loss: 0.3018 - kl_loss: 0.0102 - beta: 0.3376 - val_loss: 0.7901 - val_reconstruction_loss: 0.7650 - val_kl_loss: 0.0251 - val_beta: 0.3376 - lr: 1.5625e-06\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2882 - reconstruction_loss: 0.2763 - kl_loss: 0.0124 - beta: 0.3940 - val_loss: 0.7322 - val_reconstruction_loss: 0.7026 - val_kl_loss: 0.0296 - val_beta: 0.3940 - lr: 1.5625e-06\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2685 - reconstruction_loss: 0.2519 - kl_loss: 0.0144 - beta: 0.4504 - val_loss: 0.6721 - val_reconstruction_loss: 0.6380 - val_kl_loss: 0.0341 - val_beta: 0.4504 - lr: 1.5625e-06\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2478 - reconstruction_loss: 0.2268 - kl_loss: 0.0164 - beta: 0.5067 - val_loss: 0.6093 - val_reconstruction_loss: 0.5708 - val_kl_loss: 0.0384 - val_beta: 0.5067 - lr: 1.5625e-06\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2289 - reconstruction_loss: 0.2021 - kl_loss: 0.0184 - beta: 0.5631 - val_loss: 0.5498 - val_reconstruction_loss: 0.5072 - val_kl_loss: 0.0426 - val_beta: 0.5631 - lr: 1.5625e-06\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2058 - reconstruction_loss: 0.1779 - kl_loss: 0.0202 - beta: 0.6194 - val_loss: 0.4864 - val_reconstruction_loss: 0.4400 - val_kl_loss: 0.0465 - val_beta: 0.6194 - lr: 1.5625e-06\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1817 - reconstruction_loss: 0.1536 - kl_loss: 0.0218 - beta: 0.6758 - val_loss: 0.4259 - val_reconstruction_loss: 0.3756 - val_kl_loss: 0.0502 - val_beta: 0.6758 - lr: 1.5625e-06\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.1537 - reconstruction_loss: 0.1297 - kl_loss: 0.0234 - beta: 0.7322 - val_loss: 0.3651 - val_reconstruction_loss: 0.3115 - val_kl_loss: 0.0536 - val_beta: 0.7322 - lr: 1.5625e-06\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.1340 - reconstruction_loss: 0.1049 - kl_loss: 0.0246 - beta: 0.7885 - val_loss: 0.3018 - val_reconstruction_loss: 0.2451 - val_kl_loss: 0.0567 - val_beta: 0.7885 - lr: 1.5625e-06\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2486 - reconstruction_loss: 0.3302 - kl_loss: 0.0076 - beta: 0.1449 - val_loss: 0.9997 - val_reconstruction_loss: 0.9891 - val_kl_loss: 0.0106 - val_beta: 0.1449 - lr: 1.5625e-06\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3716 - reconstruction_loss: 0.3601 - kl_loss: 0.0057 - beta: 0.2012 - val_loss: 0.9380 - val_reconstruction_loss: 0.9229 - val_kl_loss: 0.0151 - val_beta: 0.2012 - lr: 1.5625e-06\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3415 - reconstruction_loss: 0.3348 - kl_loss: 0.0078 - beta: 0.2576 - val_loss: 0.8768 - val_reconstruction_loss: 0.8571 - val_kl_loss: 0.0197 - val_beta: 0.2576 - lr: 1.5625e-06\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3366 - reconstruction_loss: 0.3104 - kl_loss: 0.0100 - beta: 0.3140 - val_loss: 0.8174 - val_reconstruction_loss: 0.7930 - val_kl_loss: 0.0244 - val_beta: 0.3140 - lr: 1.5625e-06\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3084 - reconstruction_loss: 0.2848 - kl_loss: 0.0121 - beta: 0.3703 - val_loss: 0.7561 - val_reconstruction_loss: 0.7270 - val_kl_loss: 0.0291 - val_beta: 0.3703 - lr: 1.5625e-06\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2880 - reconstruction_loss: 0.2602 - kl_loss: 0.0144 - beta: 0.4267 - val_loss: 0.6974 - val_reconstruction_loss: 0.6636 - val_kl_loss: 0.0338 - val_beta: 0.4267 - lr: 1.5625e-06\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2624 - reconstruction_loss: 0.2356 - kl_loss: 0.0165 - beta: 0.4830 - val_loss: 0.6364 - val_reconstruction_loss: 0.5982 - val_kl_loss: 0.0382 - val_beta: 0.4830 - lr: 1.5625e-06\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2354 - reconstruction_loss: 0.2109 - kl_loss: 0.0186 - beta: 0.5394 - val_loss: 0.5748 - val_reconstruction_loss: 0.5322 - val_kl_loss: 0.0426 - val_beta: 0.5394 - lr: 1.5625e-06\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2121 - reconstruction_loss: 0.1869 - kl_loss: 0.0206 - beta: 0.5957 - val_loss: 0.5141 - val_reconstruction_loss: 0.4674 - val_kl_loss: 0.0467 - val_beta: 0.5957 - lr: 1.5625e-06\n",
      "Epoch 20/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1949 - reconstruction_loss: 0.1628 - kl_loss: 0.0222 - beta: 0.6517\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1948 - reconstruction_loss: 0.1626 - kl_loss: 0.0222 - beta: 0.6521 - val_loss: 0.4535 - val_reconstruction_loss: 0.4031 - val_kl_loss: 0.0505 - val_beta: 0.6521 - lr: 1.5625e-06\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1713 - reconstruction_loss: 0.1385 - kl_loss: 0.0238 - beta: 0.7085 - val_loss: 0.3912 - val_reconstruction_loss: 0.3368 - val_kl_loss: 0.0544 - val_beta: 0.7085 - lr: 7.8125e-07\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1412 - reconstruction_loss: 0.1140 - kl_loss: 0.0255 - beta: 0.7648 - val_loss: 0.3302 - val_reconstruction_loss: 0.2721 - val_kl_loss: 0.0581 - val_beta: 0.7648 - lr: 7.8125e-07\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1429 - reconstruction_loss: 0.1996 - kl_loss: 0.0186 - beta: 0.1212 - val_loss: 1.0254 - val_reconstruction_loss: 1.0162 - val_kl_loss: 0.0092 - val_beta: 0.1212 - lr: 7.8125e-07\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3794 - reconstruction_loss: 0.3683 - kl_loss: 0.0051 - beta: 0.1775 - val_loss: 0.9633 - val_reconstruction_loss: 0.9497 - val_kl_loss: 0.0136 - val_beta: 0.1775 - lr: 7.8125e-07\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3527 - reconstruction_loss: 0.3434 - kl_loss: 0.0072 - beta: 0.2339 - val_loss: 0.9022 - val_reconstruction_loss: 0.8841 - val_kl_loss: 0.0182 - val_beta: 0.2339 - lr: 7.8125e-07\n",
      "SAVING ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "TRAINING ITERATION 3 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3299 - reconstruction_loss: 0.3224 - kl_loss: 0.0084 - beta: 0.2903 - val_loss: 0.8441 - val_reconstruction_loss: 0.8231 - val_kl_loss: 0.0211 - val_beta: 0.2903 - lr: 7.8125e-07\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3210 - reconstruction_loss: 0.2979 - kl_loss: 0.0103 - beta: 0.3466 - val_loss: 0.7796 - val_reconstruction_loss: 0.7543 - val_kl_loss: 0.0253 - val_beta: 0.3466 - lr: 7.8125e-07\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2882 - reconstruction_loss: 0.2725 - kl_loss: 0.0122 - beta: 0.4030 - val_loss: 0.7231 - val_reconstruction_loss: 0.6935 - val_kl_loss: 0.0296 - val_beta: 0.4030 - lr: 7.8125e-07\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2663 - reconstruction_loss: 0.2481 - kl_loss: 0.0141 - beta: 0.4593 - val_loss: 0.6589 - val_reconstruction_loss: 0.6250 - val_kl_loss: 0.0339 - val_beta: 0.4593 - lr: 7.8125e-07\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2479 - reconstruction_loss: 0.2234 - kl_loss: 0.0160 - beta: 0.5157 - val_loss: 0.5987 - val_reconstruction_loss: 0.5606 - val_kl_loss: 0.0381 - val_beta: 0.5157 - lr: 7.8125e-07\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2288 - reconstruction_loss: 0.1996 - kl_loss: 0.0180 - beta: 0.5721 - val_loss: 0.5376 - val_reconstruction_loss: 0.4954 - val_kl_loss: 0.0422 - val_beta: 0.5721 - lr: 7.8125e-07\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.1939 - reconstruction_loss: 0.1739 - kl_loss: 0.0197 - beta: 0.6284 - val_loss: 0.4771 - val_reconstruction_loss: 0.4309 - val_kl_loss: 0.0461 - val_beta: 0.6284 - lr: 7.8125e-07\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1747 - reconstruction_loss: 0.1499 - kl_loss: 0.0219 - beta: 0.6848 - val_loss: 0.4151 - val_reconstruction_loss: 0.3650 - val_kl_loss: 0.0500 - val_beta: 0.6848 - lr: 7.8125e-07\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1491 - reconstruction_loss: 0.1252 - kl_loss: 0.0231 - beta: 0.7411 - val_loss: 0.3548 - val_reconstruction_loss: 0.3010 - val_kl_loss: 0.0538 - val_beta: 0.7411 - lr: 7.8125e-07\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.1258 - reconstruction_loss: 0.1004 - kl_loss: 0.0245 - beta: 0.7975 - val_loss: 0.2919 - val_reconstruction_loss: 0.2346 - val_kl_loss: 0.0573 - val_beta: 0.7975 - lr: 7.8125e-07\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3461 - reconstruction_loss: 0.3701 - kl_loss: 0.0049 - beta: 0.1538 - val_loss: 0.9926 - val_reconstruction_loss: 0.9814 - val_kl_loss: 0.0112 - val_beta: 0.1538 - lr: 7.8125e-07\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3880 - reconstruction_loss: 0.3572 - kl_loss: 0.0059 - beta: 0.2102 - val_loss: 0.9316 - val_reconstruction_loss: 0.9161 - val_kl_loss: 0.0155 - val_beta: 0.2102 - lr: 7.8125e-07\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3614 - reconstruction_loss: 0.3323 - kl_loss: 0.0079 - beta: 0.2666 - val_loss: 0.8695 - val_reconstruction_loss: 0.8497 - val_kl_loss: 0.0198 - val_beta: 0.2666 - lr: 7.8125e-07\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3146 - reconstruction_loss: 0.3113 - kl_loss: 0.0098 - beta: 0.3229 - val_loss: 0.8091 - val_reconstruction_loss: 0.7849 - val_kl_loss: 0.0242 - val_beta: 0.3229 - lr: 7.8125e-07\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3047 - reconstruction_loss: 0.2825 - kl_loss: 0.0119 - beta: 0.3793 - val_loss: 0.7479 - val_reconstruction_loss: 0.7193 - val_kl_loss: 0.0286 - val_beta: 0.3793 - lr: 7.8125e-07\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2767 - reconstruction_loss: 0.2577 - kl_loss: 0.0138 - beta: 0.4356 - val_loss: 0.6865 - val_reconstruction_loss: 0.6536 - val_kl_loss: 0.0329 - val_beta: 0.4356 - lr: 7.8125e-07\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2437 - reconstruction_loss: 0.2333 - kl_loss: 0.0159 - beta: 0.4920 - val_loss: 0.6247 - val_reconstruction_loss: 0.5874 - val_kl_loss: 0.0372 - val_beta: 0.4920 - lr: 7.8125e-07\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2250 - reconstruction_loss: 0.2082 - kl_loss: 0.0177 - beta: 0.5484 - val_loss: 0.5651 - val_reconstruction_loss: 0.5236 - val_kl_loss: 0.0415 - val_beta: 0.5484 - lr: 7.8125e-07\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2231 - reconstruction_loss: 0.1845 - kl_loss: 0.0197 - beta: 0.6047 - val_loss: 0.5039 - val_reconstruction_loss: 0.4582 - val_kl_loss: 0.0457 - val_beta: 0.6047 - lr: 7.8125e-07\n",
      "Epoch 20/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1780 - reconstruction_loss: 0.1593 - kl_loss: 0.0214 - beta: 0.6607\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1781 - reconstruction_loss: 0.1593 - kl_loss: 0.0215 - beta: 0.6611 - val_loss: 0.4433 - val_reconstruction_loss: 0.3936 - val_kl_loss: 0.0497 - val_beta: 0.6611 - lr: 7.8125e-07\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1611 - reconstruction_loss: 0.1348 - kl_loss: 0.0231 - beta: 0.7174 - val_loss: 0.3800 - val_reconstruction_loss: 0.3263 - val_kl_loss: 0.0537 - val_beta: 0.7174 - lr: 3.9062e-07\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1442 - reconstruction_loss: 0.1106 - kl_loss: 0.0248 - beta: 0.7738 - val_loss: 0.3197 - val_reconstruction_loss: 0.2620 - val_kl_loss: 0.0577 - val_beta: 0.7738 - lr: 3.9062e-07\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1659 - reconstruction_loss: 0.2537 - kl_loss: 0.0134 - beta: 0.1302 - val_loss: 1.0129 - val_reconstruction_loss: 1.0032 - val_kl_loss: 0.0097 - val_beta: 0.1302 - lr: 3.9062e-07\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3738 - reconstruction_loss: 0.3656 - kl_loss: 0.0053 - beta: 0.1865 - val_loss: 0.9556 - val_reconstruction_loss: 0.9416 - val_kl_loss: 0.0140 - val_beta: 0.1865 - lr: 3.9062e-07\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3590 - reconstruction_loss: 0.3413 - kl_loss: 0.0072 - beta: 0.2429 - val_loss: 0.8942 - val_reconstruction_loss: 0.8759 - val_kl_loss: 0.0183 - val_beta: 0.2429 - lr: 3.9062e-07\n",
      "SAVING ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "TRAINING ITERATION 4 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3251 - reconstruction_loss: 0.3188 - kl_loss: 0.0086 - beta: 0.2992 - val_loss: 0.8303 - val_reconstruction_loss: 0.8088 - val_kl_loss: 0.0216 - val_beta: 0.2992 - lr: 3.9062e-07\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3065 - reconstruction_loss: 0.2941 - kl_loss: 0.0104 - beta: 0.3556 - val_loss: 0.7726 - val_reconstruction_loss: 0.7468 - val_kl_loss: 0.0258 - val_beta: 0.3556 - lr: 3.9062e-07\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2711 - reconstruction_loss: 0.2693 - kl_loss: 0.0123 - beta: 0.4119 - val_loss: 0.7103 - val_reconstruction_loss: 0.6804 - val_kl_loss: 0.0299 - val_beta: 0.4119 - lr: 3.9062e-07\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2550 - reconstruction_loss: 0.2442 - kl_loss: 0.0142 - beta: 0.4683 - val_loss: 0.6509 - val_reconstruction_loss: 0.6169 - val_kl_loss: 0.0341 - val_beta: 0.4683 - lr: 3.9062e-07\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2460 - reconstruction_loss: 0.2200 - kl_loss: 0.0160 - beta: 0.5247 - val_loss: 0.5878 - val_reconstruction_loss: 0.5495 - val_kl_loss: 0.0382 - val_beta: 0.5247 - lr: 3.9062e-07\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2168 - reconstruction_loss: 0.1951 - kl_loss: 0.0178 - beta: 0.5810 - val_loss: 0.5257 - val_reconstruction_loss: 0.4834 - val_kl_loss: 0.0423 - val_beta: 0.5810 - lr: 3.9062e-07\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1963 - reconstruction_loss: 0.1705 - kl_loss: 0.0196 - beta: 0.6374 - val_loss: 0.4672 - val_reconstruction_loss: 0.4209 - val_kl_loss: 0.0463 - val_beta: 0.6374 - lr: 3.9062e-07\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.1760 - reconstruction_loss: 0.1460 - kl_loss: 0.0213 - beta: 0.6937 - val_loss: 0.4064 - val_reconstruction_loss: 0.3562 - val_kl_loss: 0.0502 - val_beta: 0.6937 - lr: 3.9062e-07\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1477 - reconstruction_loss: 0.1212 - kl_loss: 0.0230 - beta: 0.7501 - val_loss: 0.3442 - val_reconstruction_loss: 0.2901 - val_kl_loss: 0.0541 - val_beta: 0.7501 - lr: 3.9062e-07\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1324 - reconstruction_loss: 0.1334 - kl_loss: 0.0217 - beta: 0.1065 - val_loss: 1.0435 - val_reconstruction_loss: 1.0358 - val_kl_loss: 0.0077 - val_beta: 0.1065 - lr: 3.9062e-07\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3972 - reconstruction_loss: 0.3783 - kl_loss: 0.0042 - beta: 0.1628 - val_loss: 0.9826 - val_reconstruction_loss: 0.9708 - val_kl_loss: 0.0118 - val_beta: 0.1628 - lr: 3.9062e-07\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3636 - reconstruction_loss: 0.3528 - kl_loss: 0.0062 - beta: 0.2192 - val_loss: 0.9243 - val_reconstruction_loss: 0.9084 - val_kl_loss: 0.0159 - val_beta: 0.2192 - lr: 3.9062e-07\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3387 - reconstruction_loss: 0.3281 - kl_loss: 0.0080 - beta: 0.2755 - val_loss: 0.8573 - val_reconstruction_loss: 0.8372 - val_kl_loss: 0.0201 - val_beta: 0.2755 - lr: 3.9062e-07\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3197 - reconstruction_loss: 0.3034 - kl_loss: 0.0099 - beta: 0.3319 - val_loss: 0.7997 - val_reconstruction_loss: 0.7754 - val_kl_loss: 0.0244 - val_beta: 0.3319 - lr: 3.9062e-07\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3005 - reconstruction_loss: 0.2787 - kl_loss: 0.0118 - beta: 0.3883 - val_loss: 0.7350 - val_reconstruction_loss: 0.7065 - val_kl_loss: 0.0286 - val_beta: 0.3883 - lr: 3.9062e-07\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2722 - reconstruction_loss: 0.2542 - kl_loss: 0.0136 - beta: 0.4446 - val_loss: 0.6752 - val_reconstruction_loss: 0.6424 - val_kl_loss: 0.0328 - val_beta: 0.4446 - lr: 3.9062e-07\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2525 - reconstruction_loss: 0.2296 - kl_loss: 0.0155 - beta: 0.5010 - val_loss: 0.6143 - val_reconstruction_loss: 0.5773 - val_kl_loss: 0.0370 - val_beta: 0.5010 - lr: 3.9062e-07\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2281 - reconstruction_loss: 0.2048 - kl_loss: 0.0174 - beta: 0.5573 - val_loss: 0.5531 - val_reconstruction_loss: 0.5119 - val_kl_loss: 0.0412 - val_beta: 0.5573 - lr: 3.9062e-07\n",
      "Epoch 19/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.2055 - reconstruction_loss: 0.1808 - kl_loss: 0.0192 - beta: 0.6133\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2054 - reconstruction_loss: 0.1804 - kl_loss: 0.0192 - beta: 0.6137 - val_loss: 0.4939 - val_reconstruction_loss: 0.4486 - val_kl_loss: 0.0452 - val_beta: 0.6137 - lr: 3.9062e-07\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.1829 - reconstruction_loss: 0.1562 - kl_loss: 0.0211 - beta: 0.6701 - val_loss: 0.4322 - val_reconstruction_loss: 0.3829 - val_kl_loss: 0.0493 - val_beta: 0.6701 - lr: 1.9531e-07\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1548 - reconstruction_loss: 0.1311 - kl_loss: 0.0228 - beta: 0.7264 - val_loss: 0.3690 - val_reconstruction_loss: 0.3157 - val_kl_loss: 0.0533 - val_beta: 0.7264 - lr: 1.9531e-07\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1369 - reconstruction_loss: 0.1069 - kl_loss: 0.0246 - beta: 0.7828 - val_loss: 0.3097 - val_reconstruction_loss: 0.2524 - val_kl_loss: 0.0574 - val_beta: 0.7828 - lr: 1.9531e-07\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2144 - reconstruction_loss: 0.2895 - kl_loss: 0.0110 - beta: 0.1391 - val_loss: 1.0084 - val_reconstruction_loss: 0.9982 - val_kl_loss: 0.0102 - val_beta: 0.1391 - lr: 1.9531e-07\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3654 - reconstruction_loss: 0.3630 - kl_loss: 0.0055 - beta: 0.1955 - val_loss: 0.9461 - val_reconstruction_loss: 0.9317 - val_kl_loss: 0.0144 - val_beta: 0.1955 - lr: 1.9531e-07\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3430 - reconstruction_loss: 0.3380 - kl_loss: 0.0073 - beta: 0.2518 - val_loss: 0.8870 - val_reconstruction_loss: 0.8684 - val_kl_loss: 0.0186 - val_beta: 0.2518 - lr: 1.9531e-07\n",
      "Epoch 26/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3301 - reconstruction_loss: 0.3138 - kl_loss: 0.0092 - beta: 0.3082 - val_loss: 0.8228 - val_reconstruction_loss: 0.8000 - val_kl_loss: 0.0228 - val_beta: 0.3082 - lr: 1.9531e-07\n",
      "Epoch 27/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2930 - reconstruction_loss: 0.2890 - kl_loss: 0.0112 - beta: 0.3646 - val_loss: 0.7597 - val_reconstruction_loss: 0.7327 - val_kl_loss: 0.0270 - val_beta: 0.3646 - lr: 1.9531e-07\n",
      "Epoch 28/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2802 - reconstruction_loss: 0.2642 - kl_loss: 0.0130 - beta: 0.4209 - val_loss: 0.7005 - val_reconstruction_loss: 0.6693 - val_kl_loss: 0.0312 - val_beta: 0.4209 - lr: 1.9531e-07\n",
      "Epoch 29/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2640 - reconstruction_loss: 0.2398 - kl_loss: 0.0148 - beta: 0.4773 - val_loss: 0.6392 - val_reconstruction_loss: 0.6038 - val_kl_loss: 0.0354 - val_beta: 0.4773 - lr: 1.9531e-07\n",
      "Epoch 30/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2366 - reconstruction_loss: 0.2153 - kl_loss: 0.0167 - beta: 0.5336 - val_loss: 0.5788 - val_reconstruction_loss: 0.5391 - val_kl_loss: 0.0396 - val_beta: 0.5336 - lr: 1.9531e-07\n",
      "Epoch 31/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2139 - reconstruction_loss: 0.1904 - kl_loss: 0.0185 - beta: 0.5900 - val_loss: 0.5183 - val_reconstruction_loss: 0.4745 - val_kl_loss: 0.0438 - val_beta: 0.5900 - lr: 1.9531e-07\n",
      "Epoch 32/100\n",
      "152/157 [============================>.] - ETA: 0s - loss: 0.1972 - reconstruction_loss: 0.1671 - kl_loss: 0.0204 - beta: 0.6446\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1968 - reconstruction_loss: 0.1665 - kl_loss: 0.0204 - beta: 0.6464 - val_loss: 0.4591 - val_reconstruction_loss: 0.4112 - val_kl_loss: 0.0479 - val_beta: 0.6464 - lr: 1.9531e-07\n",
      "Epoch 33/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1621 - reconstruction_loss: 0.1411 - kl_loss: 0.0222 - beta: 0.7027 - val_loss: 0.3971 - val_reconstruction_loss: 0.3450 - val_kl_loss: 0.0521 - val_beta: 0.7027 - lr: 9.7656e-08\n",
      "Epoch 34/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1456 - reconstruction_loss: 0.1170 - kl_loss: 0.0240 - beta: 0.7591 - val_loss: 0.3342 - val_reconstruction_loss: 0.2780 - val_kl_loss: 0.0562 - val_beta: 0.7591 - lr: 9.7656e-08\n",
      "Epoch 35/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1380 - reconstruction_loss: 0.1814 - kl_loss: 0.0194 - beta: 0.1154 - val_loss: 1.0295 - val_reconstruction_loss: 1.0209 - val_kl_loss: 0.0085 - val_beta: 0.1154 - lr: 9.7656e-08\n",
      "Epoch 36/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3859 - reconstruction_loss: 0.3725 - kl_loss: 0.0047 - beta: 0.1718 - val_loss: 0.9678 - val_reconstruction_loss: 0.9551 - val_kl_loss: 0.0127 - val_beta: 0.1718 - lr: 9.7656e-08\n",
      "Epoch 37/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3645 - reconstruction_loss: 0.3479 - kl_loss: 0.0066 - beta: 0.2282 - val_loss: 0.9076 - val_reconstruction_loss: 0.8906 - val_kl_loss: 0.0169 - val_beta: 0.2282 - lr: 9.7656e-08\n",
      "SAVING ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "TRAINING ITERATION 5 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3353 - reconstruction_loss: 0.3240 - kl_loss: 0.0083 - beta: 0.2845 - val_loss: 0.8477 - val_reconstruction_loss: 0.8269 - val_kl_loss: 0.0208 - val_beta: 0.2845 - lr: 9.7656e-08\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3113 - reconstruction_loss: 0.2996 - kl_loss: 0.0103 - beta: 0.3409 - val_loss: 0.7873 - val_reconstruction_loss: 0.7623 - val_kl_loss: 0.0250 - val_beta: 0.3409 - lr: 9.7656e-08\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2889 - reconstruction_loss: 0.2748 - kl_loss: 0.0120 - beta: 0.3972 - val_loss: 0.7235 - val_reconstruction_loss: 0.6944 - val_kl_loss: 0.0291 - val_beta: 0.3972 - lr: 9.7656e-08\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2706 - reconstruction_loss: 0.2504 - kl_loss: 0.0139 - beta: 0.4536 - val_loss: 0.6689 - val_reconstruction_loss: 0.6356 - val_kl_loss: 0.0333 - val_beta: 0.4536 - lr: 9.7656e-08\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2567 - reconstruction_loss: 0.2262 - kl_loss: 0.0157 - beta: 0.5099 - val_loss: 0.6062 - val_reconstruction_loss: 0.5688 - val_kl_loss: 0.0374 - val_beta: 0.5099 - lr: 9.7656e-08\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2136 - reconstruction_loss: 0.2020 - kl_loss: 0.0179 - beta: 0.5663 - val_loss: 0.5446 - val_reconstruction_loss: 0.5030 - val_kl_loss: 0.0416 - val_beta: 0.5663 - lr: 9.7656e-08\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2071 - reconstruction_loss: 0.1769 - kl_loss: 0.0195 - beta: 0.6227 - val_loss: 0.4838 - val_reconstruction_loss: 0.4381 - val_kl_loss: 0.0457 - val_beta: 0.6227 - lr: 9.7656e-08\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.1880 - reconstruction_loss: 0.1526 - kl_loss: 0.0212 - beta: 0.6790 - val_loss: 0.4215 - val_reconstruction_loss: 0.3717 - val_kl_loss: 0.0498 - val_beta: 0.6790 - lr: 9.7656e-08\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1549 - reconstruction_loss: 0.1273 - kl_loss: 0.0230 - beta: 0.7354 - val_loss: 0.3617 - val_reconstruction_loss: 0.3078 - val_kl_loss: 0.0539 - val_beta: 0.7354 - lr: 9.7656e-08\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1287 - reconstruction_loss: 0.1027 - kl_loss: 0.0249 - beta: 0.7917 - val_loss: 0.2992 - val_reconstruction_loss: 0.2413 - val_kl_loss: 0.0580 - val_beta: 0.7917 - lr: 9.7656e-08\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2878 - reconstruction_loss: 0.3434 - kl_loss: 0.0066 - beta: 0.1481 - val_loss: 0.9995 - val_reconstruction_loss: 0.9886 - val_kl_loss: 0.0109 - val_beta: 0.1481 - lr: 9.7656e-08\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3770 - reconstruction_loss: 0.3587 - kl_loss: 0.0058 - beta: 0.2045 - val_loss: 0.9359 - val_reconstruction_loss: 0.9209 - val_kl_loss: 0.0150 - val_beta: 0.2045 - lr: 9.7656e-08\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3405 - reconstruction_loss: 0.3338 - kl_loss: 0.0076 - beta: 0.2608 - val_loss: 0.8760 - val_reconstruction_loss: 0.8569 - val_kl_loss: 0.0192 - val_beta: 0.2608 - lr: 9.7656e-08\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3132 - reconstruction_loss: 0.3092 - kl_loss: 0.0095 - beta: 0.3172 - val_loss: 0.8149 - val_reconstruction_loss: 0.7915 - val_kl_loss: 0.0233 - val_beta: 0.3172 - lr: 9.7656e-08\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3053 - reconstruction_loss: 0.2849 - kl_loss: 0.0113 - beta: 0.3735 - val_loss: 0.7544 - val_reconstruction_loss: 0.7268 - val_kl_loss: 0.0275 - val_beta: 0.3735 - lr: 9.7656e-08\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2791 - reconstruction_loss: 0.2614 - kl_loss: 0.0133 - beta: 0.4299 - val_loss: 0.6901 - val_reconstruction_loss: 0.6585 - val_kl_loss: 0.0317 - val_beta: 0.4299 - lr: 9.7656e-08\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2531 - reconstruction_loss: 0.2365 - kl_loss: 0.0151 - beta: 0.4863 - val_loss: 0.6291 - val_reconstruction_loss: 0.5932 - val_kl_loss: 0.0358 - val_beta: 0.4863 - lr: 9.7656e-08\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2585 - reconstruction_loss: 0.2129 - kl_loss: 0.0173 - beta: 0.5426 - val_loss: 0.5688 - val_reconstruction_loss: 0.5288 - val_kl_loss: 0.0400 - val_beta: 0.5426 - lr: 9.7656e-08\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2135 - reconstruction_loss: 0.1868 - kl_loss: 0.0187 - beta: 0.5990 - val_loss: 0.5066 - val_reconstruction_loss: 0.4625 - val_kl_loss: 0.0441 - val_beta: 0.5990 - lr: 9.7656e-08\n",
      "Epoch 20/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1863 - reconstruction_loss: 0.1625 - kl_loss: 0.0206 - beta: 0.6550\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1863 - reconstruction_loss: 0.1623 - kl_loss: 0.0206 - beta: 0.6553 - val_loss: 0.4459 - val_reconstruction_loss: 0.3976 - val_kl_loss: 0.0483 - val_beta: 0.6553 - lr: 9.7656e-08\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1672 - reconstruction_loss: 0.1378 - kl_loss: 0.0224 - beta: 0.7117 - val_loss: 0.3866 - val_reconstruction_loss: 0.3342 - val_kl_loss: 0.0524 - val_beta: 0.7117 - lr: 4.8828e-08\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1421 - reconstruction_loss: 0.1134 - kl_loss: 0.0243 - beta: 0.7681 - val_loss: 0.3248 - val_reconstruction_loss: 0.2682 - val_kl_loss: 0.0566 - val_beta: 0.7681 - lr: 4.8828e-08\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1570 - reconstruction_loss: 0.2233 - kl_loss: 0.0165 - beta: 0.1244 - val_loss: 1.0201 - val_reconstruction_loss: 1.0110 - val_kl_loss: 0.0092 - val_beta: 0.1244 - lr: 4.8828e-08\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3780 - reconstruction_loss: 0.3686 - kl_loss: 0.0050 - beta: 0.1808 - val_loss: 0.9640 - val_reconstruction_loss: 0.9507 - val_kl_loss: 0.0133 - val_beta: 0.1808 - lr: 4.8828e-08\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3552 - reconstruction_loss: 0.3446 - kl_loss: 0.0068 - beta: 0.2371 - val_loss: 0.9032 - val_reconstruction_loss: 0.8858 - val_kl_loss: 0.0175 - val_beta: 0.2371 - lr: 4.8828e-08\n",
      "SAVING ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "TRAINING ITERATION 6 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3266 - reconstruction_loss: 0.3201 - kl_loss: 0.0086 - beta: 0.2935 - val_loss: 0.8364 - val_reconstruction_loss: 0.8148 - val_kl_loss: 0.0215 - val_beta: 0.2935 - lr: 4.8828e-08\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3042 - reconstruction_loss: 0.2957 - kl_loss: 0.0105 - beta: 0.3498 - val_loss: 0.7796 - val_reconstruction_loss: 0.7540 - val_kl_loss: 0.0257 - val_beta: 0.3498 - lr: 4.8828e-08\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2871 - reconstruction_loss: 0.2716 - kl_loss: 0.0124 - beta: 0.4062 - val_loss: 0.7173 - val_reconstruction_loss: 0.6875 - val_kl_loss: 0.0298 - val_beta: 0.4062 - lr: 4.8828e-08\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2710 - reconstruction_loss: 0.2463 - kl_loss: 0.0141 - beta: 0.4626 - val_loss: 0.6558 - val_reconstruction_loss: 0.6219 - val_kl_loss: 0.0339 - val_beta: 0.4626 - lr: 4.8828e-08\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2523 - reconstruction_loss: 0.2220 - kl_loss: 0.0160 - beta: 0.5189 - val_loss: 0.5956 - val_reconstruction_loss: 0.5576 - val_kl_loss: 0.0381 - val_beta: 0.5189 - lr: 4.8828e-08\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2168 - reconstruction_loss: 0.1974 - kl_loss: 0.0179 - beta: 0.5753 - val_loss: 0.5329 - val_reconstruction_loss: 0.4907 - val_kl_loss: 0.0422 - val_beta: 0.5753 - lr: 4.8828e-08\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2039 - reconstruction_loss: 0.1728 - kl_loss: 0.0196 - beta: 0.6316 - val_loss: 0.4724 - val_reconstruction_loss: 0.4261 - val_kl_loss: 0.0463 - val_beta: 0.6316 - lr: 4.8828e-08\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1695 - reconstruction_loss: 0.1481 - kl_loss: 0.0215 - beta: 0.6880 - val_loss: 0.4118 - val_reconstruction_loss: 0.3613 - val_kl_loss: 0.0504 - val_beta: 0.6880 - lr: 4.8828e-08\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1640 - reconstruction_loss: 0.1239 - kl_loss: 0.0232 - beta: 0.7444 - val_loss: 0.3497 - val_reconstruction_loss: 0.2951 - val_kl_loss: 0.0545 - val_beta: 0.7444 - lr: 4.8828e-08\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1301 - reconstruction_loss: 0.1036 - kl_loss: 0.0248 - beta: 0.1007 - val_loss: 1.0477 - val_reconstruction_loss: 1.0403 - val_kl_loss: 0.0074 - val_beta: 0.1007 - lr: 4.8828e-08\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.4001 - reconstruction_loss: 0.3797 - kl_loss: 0.0042 - beta: 0.1571 - val_loss: 0.9833 - val_reconstruction_loss: 0.9717 - val_kl_loss: 0.0115 - val_beta: 0.1571 - lr: 4.8828e-08\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3586 - reconstruction_loss: 0.3553 - kl_loss: 0.0061 - beta: 0.2134 - val_loss: 0.9251 - val_reconstruction_loss: 0.9094 - val_kl_loss: 0.0157 - val_beta: 0.2134 - lr: 4.8828e-08\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3442 - reconstruction_loss: 0.3303 - kl_loss: 0.0079 - beta: 0.2698 - val_loss: 0.8627 - val_reconstruction_loss: 0.8429 - val_kl_loss: 0.0198 - val_beta: 0.2698 - lr: 4.8828e-08\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3253 - reconstruction_loss: 0.3072 - kl_loss: 0.0097 - beta: 0.3262 - val_loss: 0.8047 - val_reconstruction_loss: 0.7808 - val_kl_loss: 0.0239 - val_beta: 0.3262 - lr: 4.8828e-08\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3070 - reconstruction_loss: 0.2819 - kl_loss: 0.0116 - beta: 0.3825 - val_loss: 0.7436 - val_reconstruction_loss: 0.7155 - val_kl_loss: 0.0281 - val_beta: 0.3825 - lr: 4.8828e-08\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2829 - reconstruction_loss: 0.2568 - kl_loss: 0.0134 - beta: 0.4389 - val_loss: 0.6851 - val_reconstruction_loss: 0.6529 - val_kl_loss: 0.0323 - val_beta: 0.4389 - lr: 4.8828e-08\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2570 - reconstruction_loss: 0.2322 - kl_loss: 0.0152 - beta: 0.4952 - val_loss: 0.6217 - val_reconstruction_loss: 0.5853 - val_kl_loss: 0.0364 - val_beta: 0.4952 - lr: 4.8828e-08\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2289 - reconstruction_loss: 0.2075 - kl_loss: 0.0172 - beta: 0.5516 - val_loss: 0.5586 - val_reconstruction_loss: 0.5180 - val_kl_loss: 0.0405 - val_beta: 0.5516 - lr: 4.8828e-08\n",
      "Epoch 19/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.2102 - reconstruction_loss: 0.1834 - kl_loss: 0.0190 - beta: 0.6076\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2101 - reconstruction_loss: 0.1830 - kl_loss: 0.0189 - beta: 0.6079 - val_loss: 0.5005 - val_reconstruction_loss: 0.4558 - val_kl_loss: 0.0447 - val_beta: 0.6079 - lr: 4.8828e-08\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1886 - reconstruction_loss: 0.1593 - kl_loss: 0.0210 - beta: 0.6643 - val_loss: 0.4374 - val_reconstruction_loss: 0.3885 - val_kl_loss: 0.0488 - val_beta: 0.6643 - lr: 2.4414e-08\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1583 - reconstruction_loss: 0.1337 - kl_loss: 0.0226 - beta: 0.7207 - val_loss: 0.3763 - val_reconstruction_loss: 0.3234 - val_kl_loss: 0.0529 - val_beta: 0.7207 - lr: 2.4414e-08\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1337 - reconstruction_loss: 0.1091 - kl_loss: 0.0244 - beta: 0.7770 - val_loss: 0.3153 - val_reconstruction_loss: 0.2582 - val_kl_loss: 0.0571 - val_beta: 0.7770 - lr: 2.4414e-08\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.1778 - reconstruction_loss: 0.2711 - kl_loss: 0.0119 - beta: 0.1334 - val_loss: 1.0118 - val_reconstruction_loss: 1.0021 - val_kl_loss: 0.0098 - val_beta: 0.1334 - lr: 2.4414e-08\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3995 - reconstruction_loss: 0.3659 - kl_loss: 0.0052 - beta: 0.1897 - val_loss: 0.9519 - val_reconstruction_loss: 0.9380 - val_kl_loss: 0.0139 - val_beta: 0.1897 - lr: 2.4414e-08\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3495 - reconstruction_loss: 0.3405 - kl_loss: 0.0071 - beta: 0.2461 - val_loss: 0.8880 - val_reconstruction_loss: 0.8699 - val_kl_loss: 0.0181 - val_beta: 0.2461 - lr: 2.4414e-08\n",
      "Epoch 26/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3311 - reconstruction_loss: 0.3168 - kl_loss: 0.0091 - beta: 0.3025 - val_loss: 0.8285 - val_reconstruction_loss: 0.8062 - val_kl_loss: 0.0222 - val_beta: 0.3025 - lr: 2.4414e-08\n",
      "Epoch 27/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3134 - reconstruction_loss: 0.2917 - kl_loss: 0.0108 - beta: 0.3588 - val_loss: 0.7648 - val_reconstruction_loss: 0.7384 - val_kl_loss: 0.0264 - val_beta: 0.3588 - lr: 2.4414e-08\n",
      "Epoch 28/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2822 - reconstruction_loss: 0.2676 - kl_loss: 0.0127 - beta: 0.4152 - val_loss: 0.7079 - val_reconstruction_loss: 0.6773 - val_kl_loss: 0.0306 - val_beta: 0.4152 - lr: 2.4414e-08\n",
      "Epoch 29/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2633 - reconstruction_loss: 0.2424 - kl_loss: 0.0144 - beta: 0.4715 - val_loss: 0.6454 - val_reconstruction_loss: 0.6107 - val_kl_loss: 0.0347 - val_beta: 0.4715 - lr: 2.4414e-08\n",
      "Epoch 30/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2392 - reconstruction_loss: 0.2179 - kl_loss: 0.0163 - beta: 0.5279 - val_loss: 0.5875 - val_reconstruction_loss: 0.5487 - val_kl_loss: 0.0389 - val_beta: 0.5279 - lr: 2.4414e-08\n",
      "Epoch 31/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2211 - reconstruction_loss: 0.1933 - kl_loss: 0.0182 - beta: 0.5843 - val_loss: 0.5254 - val_reconstruction_loss: 0.4824 - val_kl_loss: 0.0430 - val_beta: 0.5843 - lr: 2.4414e-08\n",
      "Epoch 32/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1864 - reconstruction_loss: 0.1686 - kl_loss: 0.0201 - beta: 0.6403\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1864 - reconstruction_loss: 0.1682 - kl_loss: 0.0200 - beta: 0.6406 - val_loss: 0.4629 - val_reconstruction_loss: 0.4158 - val_kl_loss: 0.0471 - val_beta: 0.6406 - lr: 2.4414e-08\n",
      "Epoch 33/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1715 - reconstruction_loss: 0.1442 - kl_loss: 0.0219 - beta: 0.6970 - val_loss: 0.4011 - val_reconstruction_loss: 0.3498 - val_kl_loss: 0.0513 - val_beta: 0.6970 - lr: 1.2207e-08\n",
      "Epoch 34/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1536 - reconstruction_loss: 0.1198 - kl_loss: 0.0237 - beta: 0.7533 - val_loss: 0.3414 - val_reconstruction_loss: 0.2860 - val_kl_loss: 0.0554 - val_beta: 0.7533 - lr: 1.2207e-08\n",
      "Epoch 35/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1307 - reconstruction_loss: 0.1460 - kl_loss: 0.0216 - beta: 0.1097 - val_loss: 1.0389 - val_reconstruction_loss: 1.0308 - val_kl_loss: 0.0081 - val_beta: 0.1097 - lr: 1.2207e-08\n",
      "Epoch 36/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3995 - reconstruction_loss: 0.3755 - kl_loss: 0.0045 - beta: 0.1661 - val_loss: 0.9785 - val_reconstruction_loss: 0.9663 - val_kl_loss: 0.0122 - val_beta: 0.1661 - lr: 1.2207e-08\n",
      "Epoch 37/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3643 - reconstruction_loss: 0.3508 - kl_loss: 0.0063 - beta: 0.2224 - val_loss: 0.9146 - val_reconstruction_loss: 0.8982 - val_kl_loss: 0.0164 - val_beta: 0.2224 - lr: 1.2207e-08\n",
      "SAVING ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "TRAINING ITERATION 7 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.3379 - reconstruction_loss: 0.3267 - kl_loss: 0.0082 - beta: 0.2788 - val_loss: 0.8559 - val_reconstruction_loss: 0.8354 - val_kl_loss: 0.0205 - val_beta: 0.2788 - lr: 1.2207e-08\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3079 - reconstruction_loss: 0.3013 - kl_loss: 0.0100 - beta: 0.3351 - val_loss: 0.7912 - val_reconstruction_loss: 0.7666 - val_kl_loss: 0.0246 - val_beta: 0.3351 - lr: 1.2207e-08\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2873 - reconstruction_loss: 0.2773 - kl_loss: 0.0119 - beta: 0.3915 - val_loss: 0.7317 - val_reconstruction_loss: 0.7029 - val_kl_loss: 0.0288 - val_beta: 0.3915 - lr: 1.2207e-08\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2744 - reconstruction_loss: 0.2527 - kl_loss: 0.0137 - beta: 0.4478 - val_loss: 0.6730 - val_reconstruction_loss: 0.6401 - val_kl_loss: 0.0329 - val_beta: 0.4478 - lr: 1.2207e-08\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2498 - reconstruction_loss: 0.2282 - kl_loss: 0.0155 - beta: 0.5042 - val_loss: 0.6125 - val_reconstruction_loss: 0.5755 - val_kl_loss: 0.0370 - val_beta: 0.5042 - lr: 1.2207e-08\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2294 - reconstruction_loss: 0.2036 - kl_loss: 0.0173 - beta: 0.5606 - val_loss: 0.5500 - val_reconstruction_loss: 0.5088 - val_kl_loss: 0.0412 - val_beta: 0.5606 - lr: 1.2207e-08\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2075 - reconstruction_loss: 0.1793 - kl_loss: 0.0192 - beta: 0.6169 - val_loss: 0.4880 - val_reconstruction_loss: 0.4427 - val_kl_loss: 0.0453 - val_beta: 0.6169 - lr: 1.2207e-08\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.1820 - reconstruction_loss: 0.1550 - kl_loss: 0.0210 - beta: 0.6733 - val_loss: 0.4285 - val_reconstruction_loss: 0.3791 - val_kl_loss: 0.0494 - val_beta: 0.6733 - lr: 1.2207e-08\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.1610 - reconstruction_loss: 0.1302 - kl_loss: 0.0228 - beta: 0.7296 - val_loss: 0.3658 - val_reconstruction_loss: 0.3122 - val_kl_loss: 0.0536 - val_beta: 0.7296 - lr: 1.2207e-08\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1381 - reconstruction_loss: 0.1055 - kl_loss: 0.0247 - beta: 0.7860 - val_loss: 0.3051 - val_reconstruction_loss: 0.2473 - val_kl_loss: 0.0577 - val_beta: 0.7860 - lr: 1.2207e-08\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2344 - reconstruction_loss: 0.3063 - kl_loss: 0.0092 - beta: 0.1424 - val_loss: 1.0034 - val_reconstruction_loss: 0.9930 - val_kl_loss: 0.0105 - val_beta: 0.1424 - lr: 1.2207e-08\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3766 - reconstruction_loss: 0.3614 - kl_loss: 0.0056 - beta: 0.1987 - val_loss: 0.9395 - val_reconstruction_loss: 0.9249 - val_kl_loss: 0.0146 - val_beta: 0.1987 - lr: 1.2207e-08\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3591 - reconstruction_loss: 0.3372 - kl_loss: 0.0074 - beta: 0.2551 - val_loss: 0.8781 - val_reconstruction_loss: 0.8594 - val_kl_loss: 0.0187 - val_beta: 0.2551 - lr: 1.2207e-08\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3353 - reconstruction_loss: 0.3129 - kl_loss: 0.0093 - beta: 0.3114 - val_loss: 0.8195 - val_reconstruction_loss: 0.7966 - val_kl_loss: 0.0229 - val_beta: 0.3114 - lr: 1.2207e-08\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3025 - reconstruction_loss: 0.2876 - kl_loss: 0.0111 - beta: 0.3678 - val_loss: 0.7620 - val_reconstruction_loss: 0.7350 - val_kl_loss: 0.0270 - val_beta: 0.3678 - lr: 1.2207e-08\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2831 - reconstruction_loss: 0.2633 - kl_loss: 0.0131 - beta: 0.4242 - val_loss: 0.6991 - val_reconstruction_loss: 0.6679 - val_kl_loss: 0.0312 - val_beta: 0.4242 - lr: 1.2207e-08\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2549 - reconstruction_loss: 0.2385 - kl_loss: 0.0148 - beta: 0.4805 - val_loss: 0.6353 - val_reconstruction_loss: 0.6000 - val_kl_loss: 0.0353 - val_beta: 0.4805 - lr: 1.2207e-08\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2437 - reconstruction_loss: 0.2141 - kl_loss: 0.0166 - beta: 0.5369 - val_loss: 0.5759 - val_reconstruction_loss: 0.5365 - val_kl_loss: 0.0394 - val_beta: 0.5369 - lr: 1.2207e-08\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2099 - reconstruction_loss: 0.1891 - kl_loss: 0.0184 - beta: 0.5932 - val_loss: 0.5158 - val_reconstruction_loss: 0.4722 - val_kl_loss: 0.0436 - val_beta: 0.5932 - lr: 1.2207e-08\n",
      "Epoch 20/100\n",
      "152/157 [============================>.] - ETA: 0s - loss: 0.1941 - reconstruction_loss: 0.1661 - kl_loss: 0.0203 - beta: 0.6478\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1937 - reconstruction_loss: 0.1650 - kl_loss: 0.0203 - beta: 0.6496 - val_loss: 0.4515 - val_reconstruction_loss: 0.4038 - val_kl_loss: 0.0477 - val_beta: 0.6496 - lr: 1.2207e-08\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.1764 - reconstruction_loss: 0.1406 - kl_loss: 0.0222 - beta: 0.7059 - val_loss: 0.3905 - val_reconstruction_loss: 0.3386 - val_kl_loss: 0.0519 - val_beta: 0.7059 - lr: 6.1035e-09\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.1466 - reconstruction_loss: 0.1158 - kl_loss: 0.0239 - beta: 0.7623 - val_loss: 0.3312 - val_reconstruction_loss: 0.2752 - val_kl_loss: 0.0560 - val_beta: 0.7623 - lr: 6.1035e-09\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1452 - reconstruction_loss: 0.1936 - kl_loss: 0.0182 - beta: 0.1187 - val_loss: 1.0287 - val_reconstruction_loss: 1.0199 - val_kl_loss: 0.0087 - val_beta: 0.1187 - lr: 6.1035e-09\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3753 - reconstruction_loss: 0.3722 - kl_loss: 0.0048 - beta: 0.1750 - val_loss: 0.9690 - val_reconstruction_loss: 0.9561 - val_kl_loss: 0.0129 - val_beta: 0.1750 - lr: 6.1035e-09\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3613 - reconstruction_loss: 0.3472 - kl_loss: 0.0067 - beta: 0.2314 - val_loss: 0.9068 - val_reconstruction_loss: 0.8898 - val_kl_loss: 0.0170 - val_beta: 0.2314 - lr: 6.1035e-09\n",
      "SAVING ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "TRAINING ITERATION 8 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.3421 - reconstruction_loss: 0.3226 - kl_loss: 0.0085 - beta: 0.2877 - val_loss: 0.8411 - val_reconstruction_loss: 0.8200 - val_kl_loss: 0.0211 - val_beta: 0.2877 - lr: 6.1035e-09\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3193 - reconstruction_loss: 0.2980 - kl_loss: 0.0103 - beta: 0.3441 - val_loss: 0.7861 - val_reconstruction_loss: 0.7608 - val_kl_loss: 0.0253 - val_beta: 0.3441 - lr: 6.1035e-09\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2894 - reconstruction_loss: 0.2734 - kl_loss: 0.0121 - beta: 0.4005 - val_loss: 0.7238 - val_reconstruction_loss: 0.6944 - val_kl_loss: 0.0294 - val_beta: 0.4005 - lr: 6.1035e-09\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2615 - reconstruction_loss: 0.2488 - kl_loss: 0.0140 - beta: 0.4568 - val_loss: 0.6607 - val_reconstruction_loss: 0.6272 - val_kl_loss: 0.0336 - val_beta: 0.4568 - lr: 6.1035e-09\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2444 - reconstruction_loss: 0.2241 - kl_loss: 0.0158 - beta: 0.5132 - val_loss: 0.6015 - val_reconstruction_loss: 0.5638 - val_kl_loss: 0.0377 - val_beta: 0.5132 - lr: 6.1035e-09\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2271 - reconstruction_loss: 0.2000 - kl_loss: 0.0176 - beta: 0.5695 - val_loss: 0.5387 - val_reconstruction_loss: 0.4969 - val_kl_loss: 0.0418 - val_beta: 0.5695 - lr: 6.1035e-09\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1992 - reconstruction_loss: 0.1752 - kl_loss: 0.0195 - beta: 0.6259 - val_loss: 0.4789 - val_reconstruction_loss: 0.4329 - val_kl_loss: 0.0460 - val_beta: 0.6259 - lr: 6.1035e-09\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.1824 - reconstruction_loss: 0.1524 - kl_loss: 0.0214 - beta: 0.6823 - val_loss: 0.4182 - val_reconstruction_loss: 0.3681 - val_kl_loss: 0.0501 - val_beta: 0.6823 - lr: 6.1035e-09\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.1512 - reconstruction_loss: 0.1260 - kl_loss: 0.0232 - beta: 0.7386 - val_loss: 0.3571 - val_reconstruction_loss: 0.3028 - val_kl_loss: 0.0542 - val_beta: 0.7386 - lr: 6.1035e-09\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.1267 - reconstruction_loss: 0.1013 - kl_loss: 0.0250 - beta: 0.7950 - val_loss: 0.2956 - val_reconstruction_loss: 0.2372 - val_kl_loss: 0.0584 - val_beta: 0.7950 - lr: 6.1035e-09\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3153 - reconstruction_loss: 0.3586 - kl_loss: 0.0058 - beta: 0.1513 - val_loss: 0.9950 - val_reconstruction_loss: 0.9839 - val_kl_loss: 0.0111 - val_beta: 0.1513 - lr: 6.1035e-09\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3776 - reconstruction_loss: 0.3572 - kl_loss: 0.0059 - beta: 0.2077 - val_loss: 0.9355 - val_reconstruction_loss: 0.9202 - val_kl_loss: 0.0153 - val_beta: 0.2077 - lr: 6.1035e-09\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3513 - reconstruction_loss: 0.3327 - kl_loss: 0.0077 - beta: 0.2641 - val_loss: 0.8706 - val_reconstruction_loss: 0.8512 - val_kl_loss: 0.0194 - val_beta: 0.2641 - lr: 6.1035e-09\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3149 - reconstruction_loss: 0.3106 - kl_loss: 0.0096 - beta: 0.3204 - val_loss: 0.8118 - val_reconstruction_loss: 0.7882 - val_kl_loss: 0.0235 - val_beta: 0.3204 - lr: 6.1035e-09\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3043 - reconstruction_loss: 0.2841 - kl_loss: 0.0116 - beta: 0.3768 - val_loss: 0.7493 - val_reconstruction_loss: 0.7216 - val_kl_loss: 0.0277 - val_beta: 0.3768 - lr: 6.1035e-09\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2794 - reconstruction_loss: 0.2597 - kl_loss: 0.0133 - beta: 0.4331 - val_loss: 0.6866 - val_reconstruction_loss: 0.6548 - val_kl_loss: 0.0318 - val_beta: 0.4331 - lr: 6.1035e-09\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2563 - reconstruction_loss: 0.2346 - kl_loss: 0.0150 - beta: 0.4895 - val_loss: 0.6275 - val_reconstruction_loss: 0.5915 - val_kl_loss: 0.0359 - val_beta: 0.4895 - lr: 6.1035e-09\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2344 - reconstruction_loss: 0.2102 - kl_loss: 0.0169 - beta: 0.5458 - val_loss: 0.5661 - val_reconstruction_loss: 0.5260 - val_kl_loss: 0.0401 - val_beta: 0.5458 - lr: 6.1035e-09\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2080 - reconstruction_loss: 0.1854 - kl_loss: 0.0187 - beta: 0.6022 - val_loss: 0.5043 - val_reconstruction_loss: 0.4600 - val_kl_loss: 0.0442 - val_beta: 0.6022 - lr: 6.1035e-09\n",
      "Epoch 20/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1860 - reconstruction_loss: 0.1612 - kl_loss: 0.0206 - beta: 0.6582\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1859 - reconstruction_loss: 0.1609 - kl_loss: 0.0205 - beta: 0.6586 - val_loss: 0.4425 - val_reconstruction_loss: 0.3941 - val_kl_loss: 0.0484 - val_beta: 0.6586 - lr: 6.1035e-09\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1544 - reconstruction_loss: 0.1360 - kl_loss: 0.0224 - beta: 0.7149 - val_loss: 0.3835 - val_reconstruction_loss: 0.3310 - val_kl_loss: 0.0525 - val_beta: 0.7149 - lr: 3.0518e-09\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.1379 - reconstruction_loss: 0.1118 - kl_loss: 0.0243 - beta: 0.7713 - val_loss: 0.3218 - val_reconstruction_loss: 0.2652 - val_kl_loss: 0.0566 - val_beta: 0.7713 - lr: 3.0518e-09\n",
      "Epoch 23/100\n",
      "131/157 [========================>.....] - ETA: 0s - loss: 0.1456 - reconstruction_loss: 0.2144 - kl_loss: 0.0159 - beta: 0.1183"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRAINING ITERATION \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Iterative training. \u001b[39;00m\n\u001b[1;32m     14\u001b[0m     save_path \u001b[38;5;241m=\u001b[39m home_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/VAE_trainings/attempt2/n_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# As of 7/8/25. Should be synced with vae0_analysis\u001b[39;00m\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.12.0/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.12.0/lib/python3.9/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.12.0/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.12.0/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.12.0/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.12.0/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.12.0/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.12.0/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.12.0/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train = True\n",
    "NUM_TRAIN = 30 # For now lets just try 30\n",
    "save = True\n",
    "SAVE_PATH = home_path+f\"/VAE_trainings/attempt2/old_cyclical_beta/\"\n",
    "# Last save is in attempt 1. New save should go to attempt 2\n",
    "# Attempt History. The original code for each folder should also be tied to the commits. \n",
    "# 0: no weighted MSE, no call_backs\n",
    "# 1: adding ReduceLRonPlatueau and early_stopping and the test_step\n",
    "# 2: /old_cylcical_beta/. now training multiple times. But other wise no different from previous. This is to differentiate between the old cyclical beta and the atlas beta schedule.\n",
    "for i in range(NUM_TRAIN):\n",
    "    if train:\n",
    "        print(f\"TRAINING ITERATION {i} ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
    "        history = vae.fit(x=X_train, validation_split=0.2, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, callbacks=[early_stopping,reduce_lr], shuffle=True)\n",
    "        # Iterative training. \n",
    "        save_path = SAVE_PATH+f\"n_{i}/\" # As of 7/8/25. Should be synced with vae0_analysis\n",
    "        if save:\n",
    "            print(f\"SAVING ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
    "            vae.save_weights(filepath=save_path, save_format='tf')\n",
    "\n",
    "            # Now save the histories\n",
    "            with open(save_path + f\"training_history.pkl\", 'wb') as f:\n",
    "                pkl.dump(history.history, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05d48f9",
   "metadata": {},
   "source": [
    "Plot Loss vs epoch history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c22c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'history' is the object returned by your model.fit() call\n",
    "\n",
    "# Extract the loss values\n",
    "total_loss = history.history['loss']\n",
    "reco_loss = history.history['reconstruction_loss']\n",
    "kl_loss = history.history['kl_loss']\n",
    "val_total_loss = history.history['val_loss']\n",
    "val_reco_loss = history.history['val_reconstruction_loss']\n",
    "val_kl_loss = history.history['val_kl_loss']\n",
    "\n",
    "# Create a new figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot training losses\n",
    "plt.plot(total_loss, label='Total Loss', color='blue')\n",
    "plt.plot(reco_loss, label='Reconstruction Loss', color='green')\n",
    "plt.plot(kl_loss, label='KL Loss', color='red')\n",
    "\n",
    "# Plot validation losses\n",
    "plt.plot(val_total_loss, label='Val Total Loss', color='blue', linestyle='--')\n",
    "plt.plot(val_reco_loss, label='Val Reconstruction Loss', color='green', linestyle='--')\n",
    "plt.plot(val_kl_loss, label='Val KL Loss', color='red', linestyle='--')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
