{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b693cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\" # on NERSC filelocking is not allowed\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "# Make notebook run on other GPUS. GPT's solution ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.set_visible_devices(gpus[2], 'GPU')  # change 1 to 0, 2, 3 as needed\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# import tensorflow.math as tfmath\n",
    "import tensorflow.keras as keras\n",
    "# from scipy.optimize imporjun26t curve_fit\n",
    "# from tensorflow.keras import layers, Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "# from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sklearn.metrics as sk\n",
    "# from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import PReLU, Input, LSTM, Flatten, Concatenate, Dense, Conv2D, TimeDistributed, MaxPooling2D, LeakyReLU, ReLU, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "# from tensorflow.keras.metrics import Precision\n",
    "# # from qkeras import QActivation, QDense, QConv2D, QBatchNormalization, QConv2DBatchnorm # These don't seem to be used\n",
    "# # from qkeras import quantized_relu, quantized_bits\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "\n",
    "## import the custom models and functions\n",
    "import sys\n",
    "# NOTE: This needs to be modified to where your repo lives, path to /repo/path/VAE_FS/models/\n",
    "sys.path.append('/global/homes/j/jananinf/projs/VAE_FS/models/') \n",
    "from models import VAE_Model, Qmake_encoder_set_weights, Qmake_decoder_set_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9774118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "home_path = \"/global/cfs/cdirs/m2616/jananinf/projsIO/VAE_FS/\" # Updated to NERSC\n",
    "file_path = home_path + \"preprocessed_SNL_data.h5\"\n",
    "with h5py.File(file_path, 'r') as hf:           # Shapes:\n",
    "    X_train = hf['X_train'][:]                  # (3200000, 57)\n",
    "    X_test  = hf['X_test'][:]                   # (800000,  57)\n",
    "    Ato4l_data  = hf['Ato4l_data'][:]           # (55969,   57) Signal data? \n",
    "    hToTauTau_data  = hf['hToTauTau_data'][:]   # (691283,  57)\n",
    "    hChToTauNu_data  = hf['hChToTauNu_data'][:] # (760272,  57)\n",
    "    leptoquark_data = hf['leptoquark_data'][:]  # (340544,  57)\n",
    "    print(\"Data loaded from preprocessed_SNL_data.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9877d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SZ = 57\n",
    "H1_SZ = 32\n",
    "H2_SZ = 16\n",
    "LATENT_SZ = 3\n",
    "enc = Qmake_encoder_set_weights(INPUT_SZ, H1_SZ, H2_SZ, LATENT_SZ)\n",
    "enc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fd932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = Qmake_decoder_set_weights(INPUT_SZ, H1_SZ, H2_SZ, LATENT_SZ)\n",
    "dec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93bef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _custom_MSE(reconstruction, data):\n",
    "#     # \"We use a dataset with standardized p_T as a target so that all quantities are O(1)\" arXiv: 2108.03986 \n",
    "\n",
    "#     # Q: is the input also standardized?\n",
    "    \n",
    "#     loss = keras.losses.mse(data, reconstruction)\n",
    "#     return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593f858d",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453cfecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 16384\n",
    "STOP_PATIENCE = 15\n",
    "LR_PATIENCE = 10\n",
    "steps_per_epoch = X_train.shape[0] // BATCH_SIZE\n",
    "vae = VAE_Model(enc, dec, steps_per_epoch=steps_per_epoch, cycle_length=10, min_beta=0.1, max_beta=0.8)\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001, clipnorm=1000)\n",
    "vae.compile(optimizer=opt) # Not sure what weighted_mse is doing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd0d075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like early_stopping is needed for val_loss\n",
    "early_stopping = EarlyStopping(patience=STOP_PATIENCE, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=LR_PATIENCE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "if train:\n",
    "    history = vae.fit(x=X_train, validation_split=0.2, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, callbacks=[early_stopping,reduce_lr], shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2716cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "# Last save is in attempt 1. New save should go to attempt 2\n",
    "save_path = home_path+'/VAE_trainings/attempt1/'\n",
    "if save:\n",
    "    vae.save_weights(filepath= save_path, save_format='tf')\n",
    "\n",
    "# Attempt History. The original code for each folder should also be tied to the commits. \n",
    "# 0: no weighted MSE, no call_backs\n",
    "# 1: adding ReduceLRonPlatueau and early_stopping and the test_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c22c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'history' is the object returned by your model.fit() call\n",
    "\n",
    "# Extract the loss values\n",
    "total_loss = history.history['loss']\n",
    "reco_loss = history.history['reconstruction_loss']\n",
    "kl_loss = history.history['kl_loss']\n",
    "val_total_loss = history.history['val_loss']\n",
    "val_reco_loss = history.history['val_reconstruction_loss']\n",
    "val_kl_loss = history.history['val_kl_loss']\n",
    "\n",
    "# Create a new figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot training losses\n",
    "plt.plot(total_loss, label='Total Loss', color='blue')\n",
    "plt.plot(reco_loss, label='Reconstruction Loss', color='green')\n",
    "plt.plot(kl_loss, label='KL Loss', color='red')\n",
    "\n",
    "# Plot validation losses\n",
    "plt.plot(val_total_loss, label='Val Total Loss', color='blue', linestyle='--')\n",
    "plt.plot(val_reco_loss, label='Val Reconstruction Loss', color='green', linestyle='--')\n",
    "plt.plot(val_kl_loss, label='Val KL Loss', color='red', linestyle='--')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f87efd",
   "metadata": {},
   "source": [
    "##### Reload from the latest save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736fe484",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_enc = Qmake_encoder_set_weights(INPUT_SZ, H1_SZ, H2_SZ, LATENT_SZ)\n",
    "new_dec = Qmake_decoder_set_weights(INPUT_SZ, H1_SZ, H2_SZ, LATENT_SZ)\n",
    "new_VAE = VAE_Model(new_enc, new_dec)\n",
    "new_VAE.load_weights(save_path)\n",
    "just_enc = new_VAE.get_layer(\"encoder\") # We only need encoder output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3aa7cf",
   "metadata": {},
   "source": [
    "##### Encode data, calculate anomaly score and plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d9d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions. These are intended as the AD metric funciton in calc_anomaly_scores\n",
    "def AD_score_KL(z_mean, z_log_var):\n",
    "    kl_loss = np.mean(-0.5 * (1 + z_log_var - (z_mean) ** 2 - np.exp(z_log_var)))\n",
    "    # Comparing this to eq 2 in arXiv: 2108.03986 z_log_var = log(sigma**2)\n",
    "    return kl_loss\n",
    "\n",
    "\n",
    "def AD_score_CKL(z_mean, _): # z_log_var not used\n",
    "    CKL = np.mean(z_mean**2)\n",
    "    return CKL \n",
    "\n",
    "def AD_score_Rz(z_mean, z_log_var):\n",
    "    return z_mean**2/np.exp(z_log_var)\n",
    "\n",
    "def calc_anomaly_scores(data, encoder: keras.Model, AD_metric, debug = True):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    debug: Optional bool to skip latent space vectors that produce infinities.\n",
    "    Currently set to true as it seems only 2 specific cases are affected\n",
    "    \"\"\"\n",
    "    dat_encoded = np.array(encoder.predict(data))[0] # This outputs shape (3, len(X_test), 3). Can't find satisfactory explanation for this behavior. (len(X_test), 3) makes sense. (3, len, 3) does not\n",
    "    # Kenny only uses the first list so we'll follow that convention.\n",
    "    # has shape (len(data), 3), where col 1 is z_mean, 2 is z_log_var and z. This is by design of encoder.\n",
    "    scores = np.zeros(len(data))\n",
    "    for i in range(len(scores)):\n",
    "        z_mean, z_log_var = dat_encoded[i][0], dat_encoded[i][1]\n",
    "        score = AD_metric(z_mean, z_log_var)\n",
    "        if debug and (score == np.inf):\n",
    "            print(\"RUNTIME WARNING: inf encountered. Skipping these values\\n\"\n",
    "                  + f\"z_mean: {z_mean}\\n\"\n",
    "                  + f\"z_log_var: {z_log_var}\")\n",
    "            continue\n",
    "        scores[i] = score\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d161259d",
   "metadata": {},
   "source": [
    "##### Calculate Anamoly scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1addc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_truth_and_scores(encoder, AD_metric, debug=True):\n",
    "    bg_score = calc_anomaly_scores(X_test, encoder, AD_metric)\n",
    "    scores = []\n",
    "    truths = []\n",
    "    zeros = np.zeros(len(X_test))\n",
    "    signal_data = [leptoquark_data, Ato4l_data, hChToTauNu_data, hToTauTau_data]\n",
    "\n",
    "    # Generate Truth and score lists ready for ROC curve calculation\n",
    "    for dat in signal_data:\n",
    "        truths.append(np.concatenate((zeros, np.ones(len(dat)))))\n",
    "\n",
    "        s = calc_anomaly_scores(dat, encoder, AD_metric, debug=debug)\n",
    "        scores.append(np.concatenate((bg_score,s) ))\n",
    "\n",
    "    return (truths, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19a9dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rocs(truths, scores, fig_title):\n",
    "    target_fpr = 1e-5\n",
    "    tpr_at_target = []\n",
    "    signal_names_tex = [ # latex version\n",
    "                    \"Leptoquark\"\n",
    "                    , \"$A\\\\rightarrow 4\\ell$\"\n",
    "                    , \"$h^{\\pm}\\\\rightarrow\\\\tau \\\\nu$\"\n",
    "                    , \"$h^0\\\\rightarrow\\\\tau\\\\tau$\"\n",
    "                    ]\n",
    "    signal_names_hum = [ # human readable\n",
    "                    \"Leptoquark\"\n",
    "                    ,\"A to 4L\"\n",
    "                    , \"h to Tau Nu\"\n",
    "                    , \"h to Tau Tau\"\n",
    "                    ]\n",
    "\n",
    "    for truth, score, l in zip(truths, scores, signal_names_tex):\n",
    "        fpr, tpr, thresholds = roc_curve(truth, score)\n",
    "        auc = sk.roc_auc_score(truth, score)\n",
    "        plt.plot(fpr, tpr, label=l + f\": {str(round(auc, 3))}\") # plot roc curve\n",
    "\n",
    "\n",
    "\n",
    "        # Find tpr at fpr target\n",
    "        idx = np.argmin(np.abs(fpr - target_fpr))\n",
    "        tpr_at_target.append(tpr[idx])\n",
    "        \n",
    "    plt.plot(np.linspace(0, 1, 1000), np.linspace(0, 1, 1000), \"--\")\n",
    "    plt.vlines(10**-5, 0, 1, colors=\"r\", linestyles=\"dashed\")\n",
    "\n",
    "    # Plot teaks\n",
    "    plt.loglog()\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"fpr\")\n",
    "    plt.ylabel(\"tpr\")\n",
    "    plt.title(fig_title) \n",
    "    plt.show()\n",
    "\n",
    "    for sig_nam, tpr in zip(signal_names_hum, tpr_at_target):\n",
    "        print(sig_nam + \" TPR @ FPR 10e-5 (%): \" + f\"{tpr*100:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7487486",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, s = get_truth_and_scores(just_enc, AD_score_KL)\n",
    "plot_rocs(t, s, \"ROC Curves using $D_{KL}$ as Anomaly Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbeba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, s = get_truth_and_scores(just_enc, AD_score_CKL)\n",
    "plot_rocs(t, s, \"ROC Curves using $CKL$ as Anomaly Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c14a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, s = get_truth_and_scores(just_enc, AD_score_Rz)\n",
    "plot_rocs(t, s, \"ROC Curves using $R_z$ as Anomaly Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc90a684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
